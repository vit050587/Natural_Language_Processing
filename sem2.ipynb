{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vit050587/Natural_Language_Processing/blob/master/sem2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUotKHRULVPD"
      },
      "source": [
        "# Инструменты для работы с языком"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W5jQDITy_1D",
        "outputId": "0ecc18b7-36d0-4901-f222-f96705d8cdae"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ba5Z02VLVPK"
      },
      "source": [
        "## Задача: классификация твитов по тональности\n",
        "\n",
        "У нас есть датасет из твитов, про каждый указано, как он эмоционально окрашен: положительно или отрицательно. Задача: предсказывать эмоциональную окраску.\n",
        "\n",
        "Скачиваем куски датасета ([источник](http://study.mokoron.com/)): [положительные](https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0), [отрицательные](https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "J5YiZNCPLVPe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DFLtXAZ-LVPq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "705d9bf4-8e66-4512-b49a-d18bde1e0778"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-4e142422f4eb>:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = positive.append(negative)\n"
          ]
        }
      ],
      "source": [
        "# считываем данные и заполняем общий датасет\n",
        "positive = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Natural_Language_Processing/Lesson02/positive.csv', sep=';', usecols=[3], names=['text'])\n",
        "positive['label'] = ['positive'] * len(positive)\n",
        "negative = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Natural_Language_Processing/Lesson02/positive.csv', sep=';', usecols=[3], names=['text'])\n",
        "negative['label'] = ['negative'] * len(negative)\n",
        "df = positive.append(negative)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "j1AEISlBLVP0",
        "outputId": "5af2c39a-1240-47cd-df53-9d60cb48a00c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text     label\n",
              "114906  Спала в родительском доме, на своей кровати......  negative\n",
              "114907  RT @jebesilofyt: Эх... Мы немного решили сокра...  negative\n",
              "114908  Что происходит со мной, когда в эфире #proacti...  negative\n",
              "114909  \"Любимая,я подарю тебе эту звезду...\" Имя како...  negative\n",
              "114910  @Ma_che_rie посмотри #непытайтесьпокинутьомск ...  negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb870f43-cc22-47b0-9d5b-ad6ececdf58b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>114906</th>\n",
              "      <td>Спала в родительском доме, на своей кровати......</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114907</th>\n",
              "      <td>RT @jebesilofyt: Эх... Мы немного решили сокра...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114908</th>\n",
              "      <td>Что происходит со мной, когда в эфире #proacti...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114909</th>\n",
              "      <td>\"Любимая,я подарю тебе эту звезду...\" Имя како...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114910</th>\n",
              "      <td>@Ma_che_rie посмотри #непытайтесьпокинутьомск ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb870f43-cc22-47b0-9d5b-ad6ececdf58b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb870f43-cc22-47b0-9d5b-ad6ececdf58b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb870f43-cc22-47b0-9d5b-ad6ececdf58b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZWta7oDgLVP8"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAapBC7VLVQC"
      },
      "source": [
        "## Baseline: классификация необработанных n-грамм\n",
        "\n",
        "### Векторизаторы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "M-AvVt8XLVQD"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression # можно заменить на любимый классификатор\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSuoVoxcLVQI"
      },
      "source": [
        "Что такое n-граммы:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zeNA7732LVQJ"
      },
      "outputs": [],
      "source": [
        "from nltk import ngrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeApDOmrLVQN",
        "outputId": "9b236e6c-fb70-4f55-b376-fe90f939776a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Если',), ('б',), ('мне',), ('платили',), ('каждый',), ('раз',)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "sent = 'Если б мне платили каждый раз'.split()\n",
        "list(ngrams(sent, 1)) # униграммы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPAS0fS-LVQQ",
        "outputId": "1d181453-3c9c-4ae6-a73a-b4b95b488c93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Если', 'б'),\n",
              " ('б', 'мне'),\n",
              " ('мне', 'платили'),\n",
              " ('платили', 'каждый'),\n",
              " ('каждый', 'раз')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "list(ngrams(sent, 2)) # биграммы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d77jmVPhLVQU",
        "outputId": "94960d78-95bc-4357-aade-9f672013f1af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Если', 'б', 'мне'),\n",
              " ('б', 'мне', 'платили'),\n",
              " ('мне', 'платили', 'каждый'),\n",
              " ('платили', 'каждый', 'раз')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "list(ngrams(sent, 3)) # триграммы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xXTBrGELVQX",
        "outputId": "df197a18-5f44-4d39-8525-b3236745ec2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Если', 'б', 'мне', 'платили', 'каждый'),\n",
              " ('б', 'мне', 'платили', 'каждый', 'раз')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "list(ngrams(sent, 5)) # ... пентаграммы?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHGJBEm-LVQb"
      },
      "source": [
        "Самый простой способ извлечь фичи из текстовых данных -- векторизаторы: `CountVectorizer` и `TfidfVectorizer`\n",
        "\n",
        "Объект `CountVectorizer` делает простую вещь:\n",
        "* строит для каждого документа (каждой пришедшей ему строки) вектор размерности `n`, где `n` -- количество слов или n-грам во всём корпусе\n",
        "* заполняет каждый i-тый элемент количеством вхождений слова в данный документ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "eMqZFBTgLVQb"
      },
      "outputs": [],
      "source": [
        "vec = CountVectorizer(ngram_range=(1, 1))\n",
        "bow = vec.fit_transform(x_train) # bow -- bag of words (мешок слов)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZkpqVtILVQe"
      },
      "source": [
        "ngram_range отвечает за то, какие n-граммы мы используем в качестве фичей:<br/>\n",
        "ngram_range=(1, 1) -- униграммы<br/>\n",
        "ngram_range=(3, 3) -- триграммы<br/>\n",
        "ngram_range=(1, 3) -- униграммы, биграммы и триграммы.\n",
        "\n",
        "В vec.vocabulary_ лежит словарь: мэппинг слов к их индексам:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWRtOSzKLVQf",
        "outputId": "b6d6c98b-b630-46b3-da67-a0e43f0a50d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('22', 1552),\n",
              " ('уххх', 180554),\n",
              " ('какой', 111440),\n",
              " ('насыщенный', 129225),\n",
              " ('день', 97171),\n",
              " ('добро', 98655),\n",
              " ('зло', 107793),\n",
              " ('всё', 90298),\n",
              " ('чип', 186738),\n",
              " ('дейл', 96853)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "list(vec.vocabulary_.items())[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "hkmX3iBbLVQi",
        "outputId": "3d2d4be5-f38e-4e2c-9fb4-3081e475ede6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ8q5_59LVQm",
        "outputId": "45628d44-b97b-4cd7-caf4-ec77c77145b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.17      0.16      0.17     29000\n",
            "    positive       0.16      0.16      0.16     28456\n",
            "\n",
            "    accuracy                           0.16     57456\n",
            "   macro avg       0.16      0.16      0.16     57456\n",
            "weighted avg       0.16      0.16      0.16     57456\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAhgaYgqLVQp"
      },
      "source": [
        "Попробуем сделать то же самое для триграмм:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPWXlh6ALVQq",
        "outputId": "d171d364-7eba-4a55-ddc5-aa7c02b43372"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.20      0.18      0.19     32856\n",
            "    positive       0.06      0.07      0.07     24600\n",
            "\n",
            "    accuracy                           0.13     57456\n",
            "   macro avg       0.13      0.12      0.13     57456\n",
            "weighted avg       0.14      0.13      0.14     57456\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vec = CountVectorizer(ngram_range=(3, 3))\n",
        "bow = vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnfyJkzTLVQu"
      },
      "source": [
        "(как вы думаете, почему в результатах теперь такой разброс по сравнению с униграммами?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJABxhalLVQu"
      },
      "source": [
        "## TF-IDF векторизация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LJES2s-LVQv"
      },
      "source": [
        "`TfidfVectorizer` делает то же, что и `CountVectorizer`, но в качестве значений – tf-idf каждого слова.\n",
        "\n",
        "Как считается tf-idf:\n",
        "\n",
        "TF (term frequency) – относительная частотность слова в документе:\n",
        "$$ TF(t,d) = \\frac{n_t}{\\sum_k n_k} $$\n",
        "\n",
        "`t` -- слово (term), `d` -- документ, $n_t$ -- количество вхождений слова, $n_k$ -- количество вхождений остальных слов\n",
        "\n",
        "IDF (inverse document frequency) – обратная частота документов, в которых есть это слово:\n",
        "$$ IDF(t, D) = \\mbox{log} \\frac{|D|}{|{d : t \\in d}|} $$\n",
        "\n",
        "`t` -- слово (term), `D` -- коллекция документов\n",
        "\n",
        "Перемножаем их:\n",
        "$$TFIDF_(t,d,D) = TF(t,d) \\times IDF(i, D)$$\n",
        "\n",
        "Сакральный смысл – если слово часто встречается в одном документе, но в целом по корпусу встречается в небольшом\n",
        "количестве документов, у него высокий TF-IDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "FmEcRD28LVQ0"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWLhMl9xLVQ3",
        "outputId": "9e5c715a-af1c-44de-b601-ed0e7e70c593"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.18      0.18      0.18     29107\n",
            "    positive       0.17      0.18      0.17     28349\n",
            "\n",
            "    accuracy                           0.18     57456\n",
            "   macro avg       0.18      0.18      0.18     57456\n",
            "weighted avg       0.18      0.18      0.18     57456\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vec = TfidfVectorizer(ngram_range=(1, 1))\n",
        "bow = vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTODTRnKLVQ6"
      },
      "source": [
        "В этот раз получилось хуже :( Вернёмся к `CountVectorizer`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8v9Scpn9Y0M"
      },
      "source": [
        "## PMI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVRqLcSY0etj"
      },
      "source": [
        "Можно оценить взаимосвязь слов в корпусе и понять, какие биграммы наиболее часто встречаются в тексте. Для этого можно использовать метрику PMI (Pointwise Mutual Information) - поточечная взаимная информация. Метрика PMI для двух слов вычисляется по формуле:\n",
        "\n",
        "$$pmi(x; y) = log \\frac{p(x,y)}{p(x)p(y)} $$\n",
        "\n",
        "Здесь p(y|x) - вероятность встретить слово $y$ после $x$, $p(y)$ - вероятность встретить слово $y$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXgDwf6W6Kk5"
      },
      "source": [
        "Оценим важность биграмм в нашем обучающем корпусе."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "BrF-3Z_f1Wgo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKmiOEaW53F9",
        "outputId": "8f6fd367-a5d7-44cd-9d4b-f4f1fb7d5485"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]   Package genesis is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
            "[('+1239', '728'), ('+погода', 'крутая='), ('-Вам', 'завернуть'), ('-ДОВАЙТИ', 'АЛДСКУЛ'), ('-Зелено-карие', '-Киллджой'), ('-Киллджой', '-Котик'), ('-Корнейчук', 'затроллила'), ('-МАРИЯ', '-МИША'), ('-Маладец', '-Лол'), ('-Мамаааа', 'поправь'), ('-НЕ', 'БОЙЙСЯ'), ('-ОЗВУЧИВАТЕЛЬ', 'МУЛЬТИКОВ'), ('-САРА', '-ГОЛУБЫЕ'), ('-Я.банан', '-ахх'), ('-анал', '-абстиненция'), ('-г', 'үзээ'), ('-дайте', 'winston'), ('-иногда', '.Ностальгирую'), ('-купи', 'куру'), ('-мега', 'шизофреничная'), ('-наш', 'класс^^'), ('-он', 'выыыыыыыыыыыыыыыхоооооооооооооооодноооооооооооооооооооооооой'), ('-патлатые', '-лысый'), ('-раз', 'плёткой'), ('-умильного', 'львенка'), ('-что-то', 'неописуемое'), ('.................', 'Анникабрь'), ('.NET', 'языки.'), ('.Вы', 'ахуеете'), ('.выражаешься', '.то'), ('.нормально', 'так-/'), ('//t.co/2CJpfoet5W', 'любоп…'), ('//t.co/9SBGpdgVnd', 'Освещение'), ('//t.co/9pQlB7y2nj', 'Секундочку'), ('//t.co/BwHqij5zHM', 'аплоап'), ('//t.co/FhN0anQ2YI', 'лайкаешь'), ('//t.co/J8JCPcUmaj', 'ЧЕМУ'), ('//t.co/KNcAEz2zbP', 'Выбираешь'), ('//t.co/NJqbfDxqOX', 'энийг'), ('//t.co/OsW1JRbW2A', 'Latvija'), ('//t.co/P3oWAFEQGv', 'Удивляюсь'), ('//t.co/PBmMPL171N', 'музыкантам'), ('//t.co/Q30uC0gXtd', 'Decorating'), ('//t.co/QpmDhiIDWe', 'Галкин'), ('//t.co/STOZWWcqfj', 'СМОТРИМ'), ('//t.co/VJsPf8iCyO', 'Америкосы'), ('//t.co/VRX2DYRVhi', 'Ауэзова-Курмангазы'), ('//t.co/VvK4ky8SAP', 'woow'), ('//t.co/bUyZ8KWtdO', 'Каспер'), ('//t.co/bX1eJmKLwT', 'Фотощщщки'), ('//t.co/bd4kpXwMNW', '1300'), ('//t.co/dAHOERjUjK', 'Ааааеаеее'), ('//t.co/dsvJIQP5Tgпробки', '10баллов'), ('//t.co/dyT7qKsAUU', 'Пометка'), ('//t.co/eqm7cWkJre', 'Рыбология'), ('//t.co/feGilmZjUH', 'альцмейгера'), ('//t.co/glyipvLLIo', '.А'), ('//t.co/k1DC4qBvdT', 'Музон'), ('//t.co/kyScwmrPpl', 'вота'), ('//t.co/mfjhjeZKdQу', 'сперматозоидов'), ('//t.co/miJtjKc0Nd', 'Руками'), ('//t.co/nBaTAOq5q1', 'запрыгал'), ('//t.co/qjlwirfD3A', 'изсостоек'), ('//t.co/rn98tW2fHQ', 'דרך'), ('//t.co/vN8dQpimUY', 'Улыбaйся'), ('//t.co/xhqquwo53W', 'Национализму'), ('//t.co/zM74gneUPj', 'USB-лампочка'), ('//t.co/zcJ8CtJRed', 'Прода'), ('/Dark', 'Steam/'), ('/РЖАЧ', 'АРАБСКОЙ'), ('/вспомнила', 'лето/'), ('/монгол', 'комент/'), ('/что', 'делаешь/'), ('0,4', 'кВ'), ('02Azobova', '-САРА'), ('0leGG', 'Клевер'), ('1.5м', 'шириной'), ('1.носки', '2.ключи'), ('1000+', 'сплетников'), ('100ого', 'эпизода'), ('10_Alessa', 'мэйт'), ('10летия', 'DBSK'), ('11-ым', '.Настя'), ('11Б^^', 'мальчики-умнички'), ('11й-11а-8й-7й', 'кварталы'), ('11лет', 'полюса'), ('11ть', 'пановян'), ('11числ.12мес.13год', '14:15мин'), ('12,50', '-обед'), ('125кг', 'боевых'), ('12Tanyusha', 'пляши'), ('12тыскв', 'м=24тыс'), ('13.12.11', '10:09'), ('16-гиговую', 'флэшку'), ('17+16', 'поцентов'), ('17-и', 'летнаяя'), ('17ю', 'днюхою'), ('18-летия', 'Егорки'), ('1918', 'год-расстрел'), ('1959', 'года☝️')]\n"
          ]
        }
      ],
      "source": [
        "from nltk import collocations\n",
        "nltk.download('genesis')\n",
        "nltk.download('punkt')\n",
        "print(type(nltk.corpus.genesis.words('english-web.txt')))\n",
        "bigram_measures = collocations.BigramAssocMeasures()\n",
        "# bigram_finder.apply_freq_filter(5)\n",
        "bigram_finder = collocations.BigramCollocationFinder.from_documents([nltk.word_tokenize(x) for x in x_train])\n",
        "bigrams = bigram_finder.nbest(bigram_measures.pmi, 100)\n",
        "print(bigrams)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h4Cq1PUTTc-"
      },
      "source": [
        "Можно рассмотреть другие метрики оценки важности биграмм, например, метрику правдоподобия (подробнее про вычисление метрики можно посмотреть [здесь (пункт 5.3.4)](http://www.corpus.unam.mx/cursoenah/ManningSchutze_1999_FoundationsofStatisticalNaturalLanguageProcessing.pdf):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTOJg4KoOo84",
        "outputId": "a0713e65-0e14-4f9e-af57-2e052c5585fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(')', ')'), ('http', ':'), ('RT', '@'), (':', 'D'), ('!', '!'), (',', 'что'), (')', 'http'), ('у', 'меня'), (',', 'а'), (',', ')'), (')', ','), ('*', '*'), ('@', ')'), (':', ')'), (',', 'но'), (';', ')'), (')', ':'), (':', '*'), (':', '-'), ('у', 'нас'), (')', '@'), (',', ':'), (':', ','), ('@', ':'), (',', ','), (':', ':'), ('&', 'lt'), ('=', ')'), ('@', '@'), (':', 'DD'), ('-', ')'), (',', '@'), ('у', 'тебя'), ('lt', ';'), ('со', 'мной'), ('Доброе', 'утро'), ('и', ')'), (')', '!'), ('D', 'http'), (',', 'когда'), ('?', '?'), ('не', ')'), ('в', ')'), ('с', 'тобой'), ('новый', 'год'), (',', 'как'), ('#', 'євромайдан'), (',', 'я'), ('&', 'gt'), ('потому', 'что'), ('?', '—'), ('не', 'знаю'), (':', '-D'), ('У', 'меня'), ('все', 'равно'), ('RT', ')'), ('сих', 'пор'), ('самом', 'деле'), ('--', '--'), ('я', ')'), (':', 'DDD'), ('х', ')'), (',', 'чтобы'), (':', '!'), ('а', 'я'), (',', '!'), ('gt', ';'), (')', '#'), ('днем', 'рождения'), (')', '.'), ('об', 'этом'), ('!', ','), (';', '3'), (')', 'в'), ('?', ')'), ('D', ')'), ('а', 'потом'), ('танцы', 'офигенны'), ('“', '@'), (',', 'если'), ('с', ')'), ('и', ':'), ('что', 'я'), (')', '?'), ('не', 'могу'), ('целый', 'день'), (')', 'RT'), ('ничего', 'не'), ('!', ')'), ('спокойной', 'ночи'), (':', '.'), ('в', 'школе'), (')', 'не'), ('не', ':'), ('в', ':'), ('у', 'вас'), ('ко', 'мне'), (',', '.'), ('Серый', 'Волк'), ('идиот', 'целый')]\n"
          ]
        }
      ],
      "source": [
        "bigrams = bigram_finder.nbest(bigram_measures.likelihood_ratio, 100)\n",
        "print(bigrams)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfjCYZa8TeX_"
      },
      "source": [
        "Как можно заметить, немаловажную роль в текстах занимает пунктуация."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AJk1B39LVRP"
      },
      "source": [
        "## Стоп-слова и пунктуация\n",
        "\n",
        "*Стоп-слова* -- это слова, которые часто встречаются практически в любом тексте и ничего интересного не говорят о конретном документе, то есть играют роль шума. Поэтому их принято убирать. По той же причине убирают и пунктуацию."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpWhsTuRLVRP",
        "outputId": "8ccd66aa-33b7-452c-907d-fbf55fad914d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# у вас здесь, вероятно, выскочит ошибка и надо будет загрузить стоп слова (в тексте ошибки написано, как)\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "print(stopwords.words('russian'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OdRF7rlyLVRS",
        "outputId": "146fd302-5471-42d2-907c-0e6da02ff913"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "from string import punctuation\n",
        "punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "OfXiH98XLVRV"
      },
      "outputs": [],
      "source": [
        "noise = stopwords.words('russian') + list(punctuation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtiIhHDMLVRY"
      },
      "source": [
        "В векторизаторах за стоп-слова, логичным образом, отвечает аргумент `stop_words`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "vME5_fl82fe1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZnbarm_LVRY",
        "outputId": "ff69b4cf-6508-46a8-8338-045fea7e0ab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.15      0.15      0.15     28547\n",
            "    positive       0.16      0.16      0.16     28909\n",
            "\n",
            "    accuracy                           0.16     57456\n",
            "   macro avg       0.16      0.16      0.16     57456\n",
            "weighted avg       0.16      0.16      0.16     57456\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=noise)\n",
        "bow = vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr934O7yLVRb"
      },
      "source": [
        "Получилось чуть лучше. Что ещё можно сделать?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7O_oD1fLVRc"
      },
      "source": [
        "## Лемматизация\n",
        "\n",
        "Лемматизация – это сведение разных форм одного слова к начальной форме – *лемме*. Почему это хорошо?\n",
        "* Во-первых, мы хотим рассматривать как отдельную фичу каждое *слово*, а не каждую его отдельную форму.\n",
        "* Во-вторых, некоторые стоп-слова стоят только в начальной форме, и без лематизации выкидываем мы только её.\n",
        "\n",
        "Для русского есть два хороших лемматизатора: mystem и pymorphy:\n",
        "\n",
        "### [Mystem](https://tech.yandex.ru/mystem/)\n",
        "Как с ним работать:\n",
        "* можно скачать mystem и запускать [из терминала с разными параметрами](https://tech.yandex.ru/mystem/doc/)\n",
        "* [pymystem3](https://pythonhosted.org/pymystem3/pymystem3.html) - обертка для питона, работает медленнее, но это удобно"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96HdoB7zLVRc",
        "outputId": "ec4fa9bc-a953-4256-9e47-853737a24c20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-01 19:08:28--  http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
            "Resolving download.cdn.yandex.net (download.cdn.yandex.net)... 5.45.205.244, 5.45.205.245, 5.45.205.241, ...\n",
            "Connecting to download.cdn.yandex.net (download.cdn.yandex.net)|5.45.205.244|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: http://cachev2-spb01.cdn.yandex.net/download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz?lid=122 [following]\n",
            "--2023-07-01 19:08:29--  http://cachev2-spb01.cdn.yandex.net/download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz?lid=122\n",
            "Resolving cachev2-spb01.cdn.yandex.net (cachev2-spb01.cdn.yandex.net)... 37.9.93.112, 2a02:6b8:117:5::112\n",
            "Connecting to cachev2-spb01.cdn.yandex.net (cachev2-spb01.cdn.yandex.net)|37.9.93.112|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16457938 (16M) [application/octet-stream]\n",
            "Saving to: ‘mystem-3.0-linux3.1-64bit.tar.gz’\n",
            "\n",
            "mystem-3.0-linux3.1 100%[===================>]  15.70M  8.42MB/s    in 1.9s    \n",
            "\n",
            "2023-07-01 19:08:31 (8.42 MB/s) - ‘mystem-3.0-linux3.1-64bit.tar.gz’ saved [16457938/16457938]\n",
            "\n",
            "mystem\n"
          ]
        }
      ],
      "source": [
        "!wget http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
        "!tar -xvf mystem-3.0-linux3.1-64bit.tar.gz\n",
        "!cp mystem /bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "kzQwGwAaZWV5"
      },
      "outputs": [],
      "source": [
        "from pymystem3 import Mystem\n",
        "mystem_analyzer = Mystem()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w-_fkNtLVRf"
      },
      "source": [
        "Мы инициализировали Mystem c дефолтными параметрами. А вообще параметры есть такие:\n",
        "* mystem_bin - путь к `mystem`, если их несколько\n",
        "* grammar_info - нужна ли грамматическая информация или только леммы (по дефолту нужна)\n",
        "* disambiguation - нужно ли снятие омонимии - дизамбигуация (по дефолту нужна)\n",
        "* entire_input - нужно ли сохранять в выводе все (пробелы всякие, например), или можно выкинуть (по дефолту оставляется все)\n",
        "\n",
        "Методы Mystem принимают строку, токенизатор вшит внутри. Можно, конечно, и пословно анализировать, но тогда он не сможет учитывать контекст.\n",
        "\n",
        "Можно просто лемматизировать текст:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "fjHHLQv9txDq",
        "outputId": "1b0cc273-c525-42cc-8706-76a3b150f3d0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-4f38e8087fa8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmystem_analyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'example' is not defined"
          ]
        }
      ],
      "source": [
        "#print(mystem_analyzer.lemmatize(example))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RI1eftjkLVRi"
      },
      "source": [
        "А можно получить грамматическую информацию:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4MLqlZnxNEj"
      },
      "outputs": [],
      "source": [
        "#mystem_analyzer.analyze(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADcGtz4JLVRl"
      },
      "source": [
        "Давайте терепь используем лемматизатор майстема в качестве токенизатора."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "x48Q56tiLVRn"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def my_preproc(text):\n",
        "    text = re.sub('[{}]'.format(punctuation), '', text)\n",
        "    text = mystem_analyzer.lemmatize(text)\n",
        "    return [word for word in text if word not in stopwords.words('russian') + [' ', '\\n']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEwOQTJPLVRq",
        "outputId": "adb30b8a-f69d-4dc5-bb08-4063da351ca8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.17      0.17      0.17     28959\n",
            "    positive       0.16      0.17      0.16     28497\n",
            "\n",
            "    accuracy                           0.17     57456\n",
            "   macro avg       0.17      0.17      0.17     57456\n",
            "weighted avg       0.17      0.17      0.17     57456\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=my_preproc)\n",
        "bow = vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJlvqWuALVRs"
      },
      "source": [
        "### [Pymorphy](http://pymorphy2.readthedocs.io/en/latest/)\n",
        "Это модуль на питоне, довольно быстрый и с кучей функций."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHDkurN1zf7g",
        "outputId": "0f37ec3e-6768-4972-a9e5-521ed81fdd3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/55.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dawg-python>=0.7.1 (from pymorphy2)\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docopt>=0.6 (from pymorphy2)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13707 sha256=50e3376340beba488aef0f776407656e89abac312f431d869a4eae37345e4774\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built docopt\n",
            "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ],
      "source": [
        "!pip install pymorphy2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "7SlwsLU7LVRt"
      },
      "outputs": [],
      "source": [
        "from pymorphy2 import MorphAnalyzer\n",
        "pymorphy2_analyzer = MorphAnalyzer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qaz0x7frLVRw"
      },
      "source": [
        "pymorphy2 работает с отдельными словами. Если дать ему на вход предложение - он его просто не лемматизирует, т.к. не понимает"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdf6XoEbLVRw",
        "outputId": "f73a5786-78b0-45a0-e981-255e026ba713"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parse(word='платили', tag=OpencorporaTag('VERB,impf,tran plur,past,indc'), normal_form='платить', score=1.0, methods_stack=((DictionaryAnalyzer(), 'платили', 2472, 10),))]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "ana = pymorphy2_analyzer.parse(sent[3])\n",
        "ana"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0KuHQGPgLVRz",
        "outputId": "6d9b6c47-5e0a-4e0b-ef52-fa84839155f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'платить'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "ana[0].normal_form"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFTkF8xUARlS"
      },
      "source": [
        "### [Natasha](https://github.com/natasha/)\n",
        "\n",
        "В библиотеке natasha реализовано множество полезных библиотек для русского языка: разбиение на токены и предложения, русскоязычные word embeddings, морфологический, синтаксический анализ, лемматизация, извлечение именованных сущностей и т.д. Модуль библиотеки Razdel, основанный на правилах, предназначен для разбиения текста на токены и предложения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CVeDxeIA6rg",
        "outputId": "875e8e5b-4bd3-4187-d54a-078f3efd4f73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting razdel\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: razdel\n",
            "Successfully installed razdel-0.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install razdel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOTkw9MpAnNN",
        "outputId": "55104577-29f8-47fa-e130-3f55f345efb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Substring(0, 13, 'Кружка-термос'),\n",
              " Substring(14, 16, 'на'),\n",
              " Substring(17, 20, '0.5'),\n",
              " Substring(20, 21, 'л'),\n",
              " Substring(22, 23, '('),\n",
              " Substring(23, 28, '50/64'),\n",
              " Substring(29, 32, 'см³'),\n",
              " Substring(32, 33, ','),\n",
              " Substring(34, 37, '516'),\n",
              " Substring(37, 38, ';'),\n",
              " Substring(38, 41, '...'),\n",
              " Substring(41, 42, ')')]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "from razdel import tokenize\n",
        "\n",
        "tokens = list(tokenize('Кружка-термос на 0.5л (50/64 см³, 516;...)'))\n",
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ftx-WzUbBCpO",
        "outputId": "824f6be5-4290-44a9-d302-35dc9479ea6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Кружка-термос',\n",
              " 'на',\n",
              " '0.5',\n",
              " 'л',\n",
              " '(',\n",
              " '50/64',\n",
              " 'см³',\n",
              " ',',\n",
              " '516',\n",
              " ';',\n",
              " '...',\n",
              " ')']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "[_.text for _ in tokens]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyhsQp4MGbW8",
        "outputId": "80e0d2e0-1c30-4fde-acca-8419cd091009"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting natasha\n",
            "  Downloading natasha-1.5.0-py3-none-any.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pymorphy2 in /usr/local/lib/python3.10/dist-packages (from natasha) (0.9.1)\n",
            "Requirement already satisfied: razdel>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from natasha) (0.5.0)\n",
            "Collecting navec>=0.9.0 (from natasha)\n",
            "  Downloading navec-0.10.0-py3-none-any.whl (23 kB)\n",
            "Collecting slovnet>=0.6.0 (from natasha)\n",
            "  Downloading slovnet-0.6.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yargy>=0.14.0 (from natasha)\n",
            "  Downloading yargy-0.15.1-py3-none-any.whl (33 kB)\n",
            "Collecting ipymarkup>=0.8.0 (from natasha)\n",
            "  Downloading ipymarkup-0.9.0-py3-none-any.whl (14 kB)\n",
            "Collecting intervaltree>=3 (from ipymarkup>=0.8.0->natasha)\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from navec>=0.9.0->natasha) (1.22.4)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from pymorphy2->natasha) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.10/dist-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.10/dist-packages (from pymorphy2->natasha) (0.6.2)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
            "Building wheels for collected packages: intervaltree\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26099 sha256=94a3d36acd249404a60cecaa1348a1832f9d160cad1a74d40c0ccb33731892ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/80/8c/43488a924a046b733b64de3fac99252674c892a4c3801c0a61\n",
            "Successfully built intervaltree\n",
            "Installing collected packages: navec, intervaltree, yargy, slovnet, ipymarkup, natasha\n",
            "Successfully installed intervaltree-3.1.0 ipymarkup-0.9.0 natasha-1.5.0 navec-0.10.0 slovnet-0.6.0 yargy-0.15.1\n"
          ]
        }
      ],
      "source": [
        "!pip install natasha"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMO3jsqLKSIV"
      },
      "source": [
        "С помощью библиотеки natasha можно также лемматизировать тексты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "vJZgfRnvIS2q"
      },
      "outputs": [],
      "source": [
        "from natasha import Doc, MorphVocab, Segmenter, NewsEmbedding, NewsMorphTagger\n",
        "\n",
        "segmenter = Segmenter()\n",
        "morph_vocab = MorphVocab()\n",
        "emb = NewsEmbedding()\n",
        "morph_tagger = NewsMorphTagger(emb)\n",
        "\n",
        "def natasha_lemmatize(text):\n",
        "  doc = Doc(text)\n",
        "  doc.segment(segmenter)\n",
        "  doc.tag_morph(morph_tagger)\n",
        "  for token in doc.tokens:\n",
        "    token.lemmatize(morph_vocab)\n",
        "  return {_.text: _.lemma for _ in doc.tokens}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBtlnYlFBOKv",
        "outputId": "ac5460db-ae26-4aa1-ae5a-17a127b41582"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Посол': 'посол',\n",
              " 'Израиля': 'израиль',\n",
              " 'на': 'на',\n",
              " 'Украине': 'украина',\n",
              " 'Йоэль': 'йоэль',\n",
              " 'Лион': 'лион',\n",
              " 'признался': 'признаться',\n",
              " ',': ',',\n",
              " 'что': 'что',\n",
              " 'пришел': 'прийти',\n",
              " 'в': 'в',\n",
              " 'шок': 'шок',\n",
              " 'узнав': 'узнать',\n",
              " 'о': 'о',\n",
              " 'решении': 'решение',\n",
              " 'властей': 'власть',\n",
              " 'Львовской': 'львовский',\n",
              " 'области': 'область',\n",
              " 'объявить': 'объявить',\n",
              " '2019': '2019',\n",
              " 'год': 'год',\n",
              " 'годом': 'год',\n",
              " 'лидера': 'лидер',\n",
              " 'запрещенной': 'запретить',\n",
              " 'России': 'россия',\n",
              " 'Организации': 'организация',\n",
              " 'украинских': 'украинский',\n",
              " 'националистов': 'националист',\n",
              " '(': '(',\n",
              " 'ОУН': 'оун',\n",
              " ')': ')',\n",
              " 'Степана': 'степан',\n",
              " 'Бандеры': 'бандера',\n",
              " '.': '.',\n",
              " 'Свое': 'свой',\n",
              " 'заявление': 'заявление',\n",
              " 'он': 'он',\n",
              " 'разместил': 'разместить',\n",
              " 'Twitter': 'twitter',\n",
              " '«': '«',\n",
              " 'Я': 'я',\n",
              " 'не': 'не',\n",
              " 'могу': 'мочь',\n",
              " 'понять': 'понять',\n",
              " 'как': 'как',\n",
              " 'прославление': 'прославление',\n",
              " 'тех': 'тот',\n",
              " 'кто': 'кто',\n",
              " 'непосредственно': 'непосредственно',\n",
              " 'принимал': 'принимать',\n",
              " 'участие': 'участие',\n",
              " 'ужасных': 'ужасный',\n",
              " 'антисемитских': 'антисемитский',\n",
              " 'преступлениях': 'преступление',\n",
              " 'помогает': 'помогать',\n",
              " 'бороться': 'бороться',\n",
              " 'с': 'с',\n",
              " 'антисемитизмом': 'антисемитизм',\n",
              " 'и': 'и',\n",
              " 'ксенофобией': 'ксенофобия',\n",
              " 'Украина': 'украина',\n",
              " 'должна': 'должный',\n",
              " 'забывать': 'забывать',\n",
              " 'совершенных': 'совершить',\n",
              " 'против': 'против',\n",
              " 'евреев': 'еврей',\n",
              " 'никоим': 'никой',\n",
              " 'образом': 'образ',\n",
              " 'отмечать': 'отмечать',\n",
              " 'их': 'они',\n",
              " 'через': 'через',\n",
              " 'почитание': 'почитание',\n",
              " 'исполнителей': 'исполнитель',\n",
              " '»': '»',\n",
              " '—': '—',\n",
              " 'написал': 'написать',\n",
              " 'дипломат': 'дипломат',\n",
              " '11': '11',\n",
              " 'декабря': 'декабрь',\n",
              " 'Львовский': 'львовский',\n",
              " 'областной': 'областной',\n",
              " 'совет': 'совет',\n",
              " 'принял': 'принять',\n",
              " 'решение': 'решение',\n",
              " 'провозгласить': 'провозгласить',\n",
              " 'регионе': 'регион',\n",
              " 'связи': 'связь',\n",
              " 'празднованием': 'празднование',\n",
              " '110-летия': '110-летие',\n",
              " 'со': 'с',\n",
              " 'дня': 'день',\n",
              " 'рождения': 'рождение',\n",
              " 'Бандера': 'бандера',\n",
              " 'родился': 'родиться',\n",
              " '1': '1',\n",
              " 'января': 'январь',\n",
              " '1909': '1909',\n",
              " 'года': 'год',\n",
              " 'В': 'в',\n",
              " 'июле': 'июль',\n",
              " 'аналогичное': 'аналогичный',\n",
              " 'Житомирский': 'житомирский',\n",
              " 'начале': 'начало',\n",
              " 'месяца': 'месяц',\n",
              " 'предложением': 'предложение',\n",
              " 'к': 'к',\n",
              " 'президенту': 'президент',\n",
              " 'страны': 'страна',\n",
              " 'Петру': 'петр',\n",
              " 'Порошенко': 'порошенко',\n",
              " 'вернуть': 'вернуть',\n",
              " 'Бандере': 'бандера',\n",
              " 'звание': 'звание',\n",
              " 'Героя': 'герой',\n",
              " 'Украины': 'украина',\n",
              " 'обратились': 'обратиться',\n",
              " 'депутаты': 'депутат',\n",
              " 'Верховной': 'верховный',\n",
              " 'Рады': 'рада',\n",
              " 'Парламентарии': 'парламентарий',\n",
              " 'уверены': 'уверить',\n",
              " 'признание': 'признание',\n",
              " 'национальным': 'национальный',\n",
              " 'героем': 'герой',\n",
              " 'поможет': 'помочь',\n",
              " 'борьбе': 'борьба',\n",
              " 'подрывной': 'подрывной',\n",
              " 'деятельностью': 'деятельность',\n",
              " 'информационном': 'информационный',\n",
              " 'поле': 'поле',\n",
              " 'а': 'а',\n",
              " 'также': 'также',\n",
              " 'остановит': 'остановить',\n",
              " 'распространение': 'распространение',\n",
              " 'мифов': 'миф',\n",
              " 'созданных': 'создать',\n",
              " 'российской': 'российский',\n",
              " 'пропагандой': 'пропаганда',\n",
              " 'Степан': 'степан',\n",
              " '1909-1959': '1909-1959',\n",
              " 'был': 'быть',\n",
              " 'одним': 'один',\n",
              " 'из': 'из',\n",
              " 'лидеров': 'лидер',\n",
              " 'выступающей': 'выступать',\n",
              " 'за': 'за',\n",
              " 'создание': 'создание',\n",
              " 'независимого': 'независимый',\n",
              " 'государства': 'государство',\n",
              " 'территориях': 'территория',\n",
              " 'украиноязычным': 'украиноязычный',\n",
              " 'населением': 'население',\n",
              " '2010': '2010',\n",
              " 'году': 'год',\n",
              " 'период': 'период',\n",
              " 'президентства': 'президентство',\n",
              " 'Виктора': 'виктор',\n",
              " 'Ющенко': 'ющенко',\n",
              " 'посмертно': 'посмертно',\n",
              " 'признан': 'признать',\n",
              " 'Героем': 'герой',\n",
              " 'однако': 'однако',\n",
              " 'впоследствии': 'впоследствии',\n",
              " 'это': 'это',\n",
              " 'было': 'быть',\n",
              " 'отменено': 'отменить',\n",
              " 'судом': 'суд'}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "text = 'Посол Израиля на Украине Йоэль Лион признался, что пришел в шок, узнав о решении властей Львовской области объявить 2019 год годом лидера запрещенной в России Организации украинских националистов (ОУН) Степана Бандеры. Свое заявление он разместил в Twitter. «Я не могу понять, как прославление тех, кто непосредственно принимал участие в ужасных антисемитских преступлениях, помогает бороться с антисемитизмом и ксенофобией. Украина не должна забывать о преступлениях, совершенных против украинских евреев, и никоим образом не отмечать их через почитание их исполнителей», — написал дипломат. 11 декабря Львовский областной совет принял решение провозгласить 2019 год в регионе годом Степана Бандеры в связи с празднованием 110-летия со дня рождения лидера ОУН (Бандера родился 1 января 1909 года). В июле аналогичное решение принял Житомирский областной совет. В начале месяца с предложением к президенту страны Петру Порошенко вернуть Бандере звание Героя Украины обратились депутаты Верховной Рады. Парламентарии уверены, что признание Бандеры национальным героем поможет в борьбе с подрывной деятельностью против Украины в информационном поле, а также остановит «распространение мифов, созданных российской пропагандой». Степан Бандера (1909-1959) был одним из лидеров Организации украинских националистов, выступающей за создание независимого государства на территориях с украиноязычным населением. В 2010 году в период президентства Виктора Ющенко Бандера был посмертно признан Героем Украины, однако впоследствии это решение было отменено судом. '\n",
        "\n",
        "natasha_lemmatize(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rck5OVqhLVSA"
      },
      "source": [
        "### mystem vs. pymorphy vs. natasha\n",
        "\n",
        "1) *Мы надеемся, что вы пользуетесь линуксом*, но mystem работает невероятно медленно под windows на больших текстах.\n",
        "\n",
        "2) *Снятие омонимии*. Mystem умеет снимать омонимию по контексту (хотя не всегда преуспевает), pymorphy2 берет на вход одно слово и соответственно вообще не умеет дизамбигуировать по контексту, natasha тоже с этим тоже не справляется успешно:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "kH2GQ4ddLVSB"
      },
      "outputs": [],
      "source": [
        "homonym1 = 'За время обучения я прослушал больше сорока курсов.'\n",
        "homonym2 = 'Сорока своровала блестящее украшение со стола.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwF-XsjeI3eX",
        "outputId": "5550ae0e-8548-42f8-ba91-175d36b67fc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'analysis': [{'lex': 'сорок', 'wt': 0.8710292578, 'gr': 'NUM=(пр|дат|род|твор)'}], 'text': 'сорока'}\n",
            "{'analysis': [{'lex': 'сорока', 'wt': 0.1210970059, 'gr': 'S,жен,од=им,ед'}], 'text': 'Сорока'}\n"
          ]
        }
      ],
      "source": [
        "mystem_analyzer = Mystem() # инициализирую объект с дефолтными параметрами\n",
        "\n",
        "print(mystem_analyzer.analyze(homonym1)[-5])\n",
        "print(mystem_analyzer.analyze(homonym2)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9jezRVlFmDo",
        "outputId": "44defc03-9ff1-4090-e2a0-1cb640eba1e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'За': 'за', 'время': 'время', 'обучения': 'обучение', 'я': 'я', 'прослушал': 'прослушать', 'больше': 'большой', 'сорока': 'сорок', 'курсов': 'курс', '.': '.'}\n"
          ]
        }
      ],
      "source": [
        "print(natasha_lemmatize(homonym1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXjGBQPoI9gl",
        "outputId": "c612c05a-2c5f-49c7-bb0b-3cea4a8efb6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Сорока': 'сорок', 'своровала': 'своровать', 'блестящее': 'блестящий', 'украшение': 'украшение', 'со': 'с', 'стола': 'стол', '.': '.'}\n"
          ]
        }
      ],
      "source": [
        "print(natasha_lemmatize(homonym2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP5qFnilLVSI"
      },
      "source": [
        "## Словарь, закон Ципфа и закон Хипса"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1umtd3OLVSI"
      },
      "source": [
        "Закон Ципфа -- эмпирическая закономерность: если все слова корпуса текста упорядочить по убыванию частоты их использования, то частота n-го слова в таком списке окажется приблизительно обратно пропорциональной его порядковому номеру n. Иными словами, частотность слов убывает очень быстро."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "lY0cWJ7eLVSJ"
      },
      "outputs": [],
      "source": [
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIjqSVjpLVSL",
        "outputId": "5805e34b-2ad1-41d6-c6ae-dce08c2bfedd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2993652\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['first_timee', 'хоть', 'я', 'и', 'школота', 'но', 'поверь', 'у', 'нас', 'то']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "corpus = [token for tweet in df.text for token in word_tokenize(tweet) if token not in punctuation]\n",
        "print(len(corpus))\n",
        "corpus[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "_oWC7NpkLVSO",
        "outputId": "124cfaa9-7658-4e89-dd27-998eeaf0ce5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('и', 58672),\n",
              " ('не', 54862),\n",
              " ('в', 54194),\n",
              " ('я', 49296),\n",
              " ('http', 44944),\n",
              " ('RT', 44070),\n",
              " ('на', 37048),\n",
              " ('D', 33020),\n",
              " ('с', 30626),\n",
              " ('что', 30440)]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "freq_dict = Counter(corpus)\n",
        "freq_dict_sorted= sorted(freq_dict.items(), key=lambda x: -x[1])\n",
        "list(freq_dict_sorted)[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "FrPkce0SLVSQ",
        "outputId": "17db6530-2b3e-4990-84f6-afb999cd1d53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "first_100_freqs = [freq for word, freq in freq_dict_sorted[:100]]\n",
        "plt.plot(first_100_freqs)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_N5V_K-LVSU"
      },
      "source": [
        "Закон Хипса -- обратная сторона закона Ципфа. Он описывает, что чем больше корпус, тем меньше новых слов добавляется с добавлением новых текстов. В какой-то момент корпус насыщается."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw0GieJSMU-O"
      },
      "source": [
        "## Задание 1.\n",
        "\n",
        "**Задание**: обучите три классификатора:\n",
        "\n",
        "1) на токенах с высокой частотой\n",
        "\n",
        "2) на токенах со средней частотой\n",
        "\n",
        "3) на токенах с низкой частотой\n",
        "\n",
        "Сравните полученные результаты, оцените какие токены наиболее важные для классификации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "QUQ6kAgPMqNn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a1a757d-22a9-49c4-aaad-8f015ddce549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "my_stopwords = stopwords.words('russian')\n",
        "# noise = stopwords.words('russian') + list(punctuation)\n",
        "noise = stopwords.words('russian')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# считываем данные и заполняем общий датасет\n",
        "positive = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Natural_Language_Processing/Lesson02/positive.csv', sep=';', usecols=[3], names=['text'])\n",
        "positive['label'] = ['positive'] * len(positive)\n",
        "negative = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Natural_Language_Processing/Lesson02/negative.csv', sep=';', usecols=[3], names=['text'])\n",
        "negative['label'] = ['negative'] * len(negative)\n",
        "df = positive.append(negative)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBIGwXR74oF6",
        "outputId": "f110fbf2-588b-44d6-ca56-fb480b436bd4"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-57-440f9aab0239>:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = positive.append(negative)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "gvtsssCt4qI1",
        "outputId": "ed0c6c03-de92-41fe-d660-8c88123a8ead"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text     label\n",
              "0       @first_timee хоть я и школота, но поверь, у на...  positive\n",
              "1       Да, все-таки он немного похож на него. Но мой ...  positive\n",
              "2       RT @KatiaCheh: Ну ты идиотка) я испугалась за ...  positive\n",
              "3       RT @digger2912: \"Кто то в углу сидит и погибае...  positive\n",
              "4       @irina_dyshkant Вот что значит страшилка :D\\nН...  positive\n",
              "...                                                   ...       ...\n",
              "111918  Но не каждый хочет что то исправлять:( http://...  negative\n",
              "111919  скучаю так :-( только @taaannyaaa вправляет мо...  negative\n",
              "111920          Вот и в школу, в говно это идти уже надо(  negative\n",
              "111921  RT @_Them__: @LisaBeroud Тауриэль, не грусти :...  negative\n",
              "111922  Такси везет меня на работу. Раздумываю приплат...  negative\n",
              "\n",
              "[226834 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25f5a004-edbe-4247-8f15-01c4c4540a3c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@first_timee хоть я и школота, но поверь, у на...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Да, все-таки он немного похож на него. Но мой ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT @KatiaCheh: Ну ты идиотка) я испугалась за ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @digger2912: \"Кто то в углу сидит и погибае...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@irina_dyshkant Вот что значит страшилка :D\\nН...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111918</th>\n",
              "      <td>Но не каждый хочет что то исправлять:( http://...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111919</th>\n",
              "      <td>скучаю так :-( только @taaannyaaa вправляет мо...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111920</th>\n",
              "      <td>Вот и в школу, в говно это идти уже надо(</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111921</th>\n",
              "      <td>RT @_Them__: @LisaBeroud Тауриэль, не грусти :...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111922</th>\n",
              "      <td>Такси везет меня на работу. Раздумываю приплат...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>226834 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25f5a004-edbe-4247-8f15-01c4c4540a3c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-25f5a004-edbe-4247-8f15-01c4c4540a3c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-25f5a004-edbe-4247-8f15-01c4c4540a3c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label)"
      ],
      "metadata": {
        "id": "ge7RbA3V4tPS"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tokens_importance(maxdf, mindf):\n",
        "\n",
        "    tfidf_vect = TfidfVectorizer(max_df=maxdf, # не берем слова что выше тресхолда\n",
        "                                 min_df=mindf, # не берем что ниже тресхолда\n",
        "#                                  max_features=1000,\n",
        "#                                  stop_words=noise,\n",
        "                                 )\n",
        "\n",
        "    bow = tfidf_vect.fit_transform(x_train)\n",
        "    clf = LogisticRegression(random_state=42)\n",
        "    clf.fit(bow, y_train)\n",
        "\n",
        "    pred = clf.predict(tfidf_vect.transform(x_test))\n",
        "    print(f'max_df= {maxdf} min_df= {mindf}')\n",
        "    print(classification_report(pred, y_test))"
      ],
      "metadata": {
        "id": "2BmXrazj4vzZ"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Берем все токены - f1-score получается низкая\n",
        "get_tokens_importance(1, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyRtZux74yBh",
        "outputId": "02ffc28d-7bc7-4dbf-945c-a950a2675e09"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_df= 1 min_df= 1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.90      0.53      0.66     47509\n",
            "    positive       0.22      0.68      0.33      9200\n",
            "\n",
            "    accuracy                           0.55     56709\n",
            "   macro avg       0.56      0.60      0.50     56709\n",
            "weighted avg       0.79      0.55      0.61     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Берем токены часто встречающиеся\n",
        "get_tokens_importance(1.0, 0.285)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdjtmBhV40CL",
        "outputId": "36176cd9-5bce-45ba-aa90-4f4abdcc6f78"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_df= 1.0 min_df= 0.285\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.35      0.60      0.44     16366\n",
            "    positive       0.77      0.55      0.64     40343\n",
            "\n",
            "    accuracy                           0.56     56709\n",
            "   macro avg       0.56      0.57      0.54     56709\n",
            "weighted avg       0.65      0.56      0.58     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Берем токены средне встречающиеся\n",
        "get_tokens_importance(0.7, 0.15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYHT4Fpl41ta",
        "outputId": "739a4975-3413-4af3-d80f-b99fa01849bc"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_df= 0.7 min_df= 0.15\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.35      0.60      0.44     16087\n",
            "    positive       0.78      0.55      0.64     40622\n",
            "\n",
            "    accuracy                           0.56     56709\n",
            "   macro avg       0.56      0.58      0.54     56709\n",
            "weighted avg       0.65      0.56      0.59     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Берем токены низкочастотные\n",
        "get_tokens_importance(0.3, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnpaOI3z4338",
        "outputId": "0ac37e49-2ecd-48fb-fcf9-0ecdb8194d4a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_df= 0.3 min_df= 1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.73      0.76      0.75     26883\n",
            "    positive       0.78      0.75      0.76     29826\n",
            "\n",
            "    accuracy                           0.76     56709\n",
            "   macro avg       0.76      0.76      0.76     56709\n",
            "weighted avg       0.76      0.76      0.76     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Судя по метрикам, низкочастотные токены наиболее важны для классификации"
      ],
      "metadata": {
        "id": "iuFLVu7647BQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV3fmzp-LVSU"
      },
      "source": [
        "## О важности эксплоративного анализа\n",
        "\n",
        "Но иногда пунктуация бывает и не шумом -- главное отталкиваться от задачи. Что будет если вообще не убирать пунктуацию?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "qjkMxK9VLVSV",
        "outputId": "d77e072b-8e47-46fe-c856-9dcc3190051c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      1.00      1.00     28010\n",
            "    positive       1.00      1.00      1.00     28699\n",
            "\n",
            "    accuracy                           1.00     56709\n",
            "   macro avg       1.00      1.00      1.00     56709\n",
            "weighted avg       1.00      1.00      1.00     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize)\n",
        "bow = vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2fRbUAvLVSX"
      },
      "source": [
        "Шок! Стоило оставить пунктуацию -- и все метрики равны 1. Как это получилось? Среди неё были очень значимые токены (как вы думаете, какие?). Найдите фичи с самыми большими коэффициэнтами:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuyKByLyyKWr"
      },
      "source": [
        "## Задание 2.\n",
        "\n",
        "найти фичи с наибольшей значимостью, и вывести их"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "2cbmcb4XyKWr"
      },
      "outputs": [],
      "source": [
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "b_JRuyuRLVSY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e3c594d-1224-42d3-f662-bddd4f5f4282"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4027088\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@', 'first_timee', 'хоть', 'я', 'и', 'школота', ',', 'но', 'поверь', ',']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "# corpus = [token for tweet in df.text for token in word_tokenize(tweet) if token not in punctuation]\n",
        "corpus = [token for tweet in df.text for token in word_tokenize(tweet)]\n",
        "print(len(corpus))\n",
        "corpus[:10]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freq_dict = Counter(corpus)\n",
        "freq_dict_sorted= sorted(freq_dict.items(), key=lambda x: -x[1])\n",
        "list(freq_dict_sorted)[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss7hUabK5H7d",
        "outputId": "bea0e55a-ef5e-45a1-88a3-a2f985a54e99"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('(', 212404),\n",
              " (')', 194005),\n",
              " (',', 188295),\n",
              " (':', 177675),\n",
              " ('@', 149978),\n",
              " ('не', 69472),\n",
              " ('!', 66923),\n",
              " ('.', 57623),\n",
              " ('и', 55166),\n",
              " ('в', 52902)]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vtAyItvLVSb"
      },
      "source": [
        "Посмотрим, как один из супер-значительных токенов справится с классификацией безо всякого машинного обучения:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "uqH07o-7LVSc",
        "outputId": "d4873c7f-7297-473c-a6c8-c32e61df2179",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.87      0.51      0.64     48263\n",
            "    positive       0.17      0.57      0.26      8446\n",
            "\n",
            "    accuracy                           0.52     56709\n",
            "   macro avg       0.52      0.54      0.45     56709\n",
            "weighted avg       0.77      0.52      0.58     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cool_token = '!'\n",
        "pred = ['positive' if cool_token in tweet else 'negative' for tweet in x_test]\n",
        "print(classification_report(pred, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cool_token = ':'\n",
        "pred = ['positive' if cool_token in tweet else 'negative' for tweet in x_test]\n",
        "print(classification_report(pred, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7fGIyCe5UBQ",
        "outputId": "fe12a9fd-6b65-4b9f-c4b4-cd312f9615aa"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.49      0.55      0.52     24915\n",
            "    positive       0.61      0.55      0.58     31794\n",
            "\n",
            "    accuracy                           0.55     56709\n",
            "   macro avg       0.55      0.55      0.55     56709\n",
            "weighted avg       0.55      0.55      0.55     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cool_token = ')'\n",
        "pred = ['positive' if cool_token in tweet else 'negative' for tweet in x_test]\n",
        "print(classification_report(pred, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAGuhQQa5V0j",
        "outputId": "721a77c9-5de8-448c-ceaa-a5a7009b437e"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      0.85      0.92     33041\n",
            "    positive       0.83      1.00      0.90     23668\n",
            "\n",
            "    accuracy                           0.91     56709\n",
            "   macro avg       0.91      0.92      0.91     56709\n",
            "weighted avg       0.93      0.91      0.91     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\")\" Это часть смайлика или сам смайлик - и его присутствие в твите в основном говорит о положительном твите и наоборот."
      ],
      "metadata": {
        "id": "sItQtHS85YTQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5THCOjMLVSg"
      },
      "source": [
        "## Символьные n-граммы\n",
        "\n",
        "Теперь в качестве фичей используем, например, униграммы символов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "AIUwDOabLVSh",
        "outputId": "5f804fa6-81a7-4779-8192-34eda5460458",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.99      1.00      1.00     27942\n",
            "    positive       1.00      0.99      1.00     28767\n",
            "\n",
            "    accuracy                           1.00     56709\n",
            "   macro avg       1.00      1.00      1.00     56709\n",
            "weighted avg       1.00      1.00      1.00     56709\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vec = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
        "bow = vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_E0uPpgLVSj"
      },
      "source": [
        "В общем-то, теперь уже понятно, почему на этих данных здесь 1. Так или инчае, на символах классифицировать тоже можно: для некторых задач (например, для определения языка) фичи-символьные n-граммы решительно рулят.\n",
        "\n",
        "Ещё одна замечательная особенность фичей-символов: токенизация и лемматизация не нужна, можно использовать такой подход для языков, у которых нет готвых анализаторов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqMFNHauyKWs"
      },
      "source": [
        "### Задание 3.\n",
        "\n",
        "1) сравнить count/tf-idf/hashing векторайзеры/полносвязанную сетку (построить classification_report)\n",
        "\n",
        "2) подобрать оптимальный размер для hashing векторайзера\n",
        "\n",
        "3) убедиться что для сетки нет переобучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRrHAQvTyKWs",
        "outputId": "b710c7e1-bd4f-454f-baf8-d129563162ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.76      0.75      0.76     28352\n",
            "    positive       0.76      0.76      0.76     28357\n",
            "\n",
            "    accuracy                           0.76     56709\n",
            "   macro avg       0.76      0.76      0.76     56709\n",
            "weighted avg       0.76      0.76      0.76     56709\n",
            "\n",
            "CPU times: user 18.5 s, sys: 10.9 s, total: 29.5 s\n",
            "Wall time: 21.4 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "count_vect = CountVectorizer()\n",
        "bow = count_vect.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "\n",
        "pred = clf.predict(count_vect.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9x6ORgkyKWs",
        "outputId": "4cb62838-0488-45df-c9f7-b7b1a60678d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.73      0.76      0.75     26883\n",
            "    positive       0.78      0.75      0.76     29826\n",
            "\n",
            "    accuracy                           0.76     56709\n",
            "   macro avg       0.76      0.76      0.76     56709\n",
            "weighted avg       0.76      0.76      0.76     56709\n",
            "\n",
            "CPU times: user 21.5 s, sys: 13.1 s, total: 34.5 s\n",
            "Wall time: 25 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "tfidf_vect = TfidfVectorizer()\n",
        "bow = tfidf_vect.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "\n",
        "pred = clf.predict(tfidf_vect.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "import sklearn\n",
        "from sklearn import linear_model"
      ],
      "metadata": {
        "id": "97K6_svu56vl"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "feature_sizes = [100, 1000, 10000, 100000, 1000000]\n",
        "\n",
        "for feature_size in feature_sizes:\n",
        "\n",
        "    h_vect = HashingVectorizer(n_features=feature_size)\n",
        "    h_vect.fit(x_train)\n",
        "\n",
        "    xtrain_count =  h_vect.transform(x_train)\n",
        "    xtest_count =  h_vect.transform(x_test)\n",
        "\n",
        "    classifier = linear_model.LogisticRegression()\n",
        "    classifier.fit(xtrain_count, y_train)\n",
        "    predictions = classifier.predict(xtest_count)\n",
        "    #predictions\n",
        "    print(f'Длина hash-вектора: {feature_size}')\n",
        "    print(classification_report(predictions, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85pZE03258hX",
        "outputId": "f123c264-d4fc-4ad1-9349-115145544580"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Длина hash-вектора: 100\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.57      0.59      0.58     27196\n",
            "    positive       0.61      0.59      0.60     29513\n",
            "\n",
            "    accuracy                           0.59     56709\n",
            "   macro avg       0.59      0.59      0.59     56709\n",
            "weighted avg       0.59      0.59      0.59     56709\n",
            "\n",
            "Длина hash-вектора: 1000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.63      0.65      0.64     27254\n",
            "    positive       0.67      0.65      0.66     29455\n",
            "\n",
            "    accuracy                           0.65     56709\n",
            "   macro avg       0.65      0.65      0.65     56709\n",
            "weighted avg       0.65      0.65      0.65     56709\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Длина hash-вектора: 10000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.70      0.71      0.71     27303\n",
            "    positive       0.73      0.71      0.72     29406\n",
            "\n",
            "    accuracy                           0.71     56709\n",
            "   macro avg       0.71      0.71      0.71     56709\n",
            "weighted avg       0.71      0.71      0.71     56709\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Длина hash-вектора: 100000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.72      0.75      0.73     26942\n",
            "    positive       0.76      0.73      0.75     29767\n",
            "\n",
            "    accuracy                           0.74     56709\n",
            "   macro avg       0.74      0.74      0.74     56709\n",
            "weighted avg       0.74      0.74      0.74     56709\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Длина hash-вектора: 1000000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.73      0.75      0.74     27139\n",
            "    positive       0.76      0.74      0.75     29570\n",
            "\n",
            "    accuracy                           0.75     56709\n",
            "   macro avg       0.75      0.75      0.75     56709\n",
            "weighted avg       0.75      0.75      0.75     56709\n",
            "\n",
            "CPU times: user 1min 16s, sys: 33.5 s, total: 1min 49s\n",
            "Wall time: 1min 20s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn import preprocessing\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, Conv1D, GRU, LSTM, Dropout\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization # формирует словарь как CountVect и TF-IDF\n",
        "# из унгикальных токенов и заменяет кажддый токен его айдишником"
      ],
      "metadata": {
        "id": "yQNZjg6S5_wO"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Привеедм y к 0,1\n",
        "\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_test = encoder.fit_transform(y_test)"
      ],
      "metadata": {
        "id": "KKauI1Sd6BYg"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "valid_data = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
      ],
      "metadata": {
        "id": "EyQbZ_bg6DIO"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.batch(16)\n",
        "valid_data = valid_data.batch(16)"
      ],
      "metadata": {
        "id": "v4Ay8c2i6Eon"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for raw in train_data.take(1):\n",
        "    pass"
      ],
      "metadata": {
        "id": "oKCStBE86GSm"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQOItEyN6Iao",
        "outputId": "41512164-391f-4b4c-922b-cedd2555bc88"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(16,), dtype=string, numpy=\n",
              " array([b'\\xd1\\x8f \\xd1\\x82\\xd0\\xb0\\xd0\\xba \\xd1\\x81\\xd0\\xbc\\xd0\\xb5\\xd1\\x88\\xd0\\xbd\\xd0\\xbe \\xd0\\xb5\\xd0\\xbc \\xd0\\xbd\\xd0\\xb0 \\xd0\\xbf\\xd1\\x83\\xd0\\xb1\\xd0\\xbb\\xd0\\xb8\\xd0\\xba\\xd0\\xb5, \\xd0\\xb2\\xd1\\x81\\xd0\\xb5 \\xd0\\xbf\\xd0\\xbe\\xd1\\x82\\xd0\\xbe\\xd0\\xbc\\xd1\\x83, \\xd1\\x87\\xd1\\x82\\xd0\\xbe \\xd1\\x81\\xd1\\x82\\xd0\\xb5\\xd1\\x81\\xd0\\xbd\\xd1\\x8f\\xd1\\x8e\\xd1\\x81\\xd1\\x8c:(',\n",
              "        b'RT @NastyaKr_: \\xd0\\x92 \\xd0\\xbf\\xd1\\x80\\xd0\\xb5\\xd0\\xb4\\xd0\\xb2\\xd0\\xba\\xd1\\x83\\xd1\\x88\\xd0\\xb5\\xd0\\xbd\\xd0\\xb8\\xd0\\xb8 \\xd0\\xbd\\xd0\\xbe\\xd0\\xb2\\xd0\\xbe\\xd0\\xb3\\xd0\\xbe \\xd0\\xb0\\xd0\\xbb\\xd1\\x8c\\xd0\\xb1\\xd0\\xbe\\xd0\\xbc\\xd0\\xb0 \\xd0\\xbe\\xd1\\x82 @eminofficial \\xd1\\x80\\xd0\\xbe\\xd0\\xb4\\xd0\\xb8\\xd0\\xbb\\xd0\\xb0\\xd1\\x81\\xd1\\x8c \\xd0\\xb2\\xd0\\xbe\\xd1\\x82 \\xd1\\x82\\xd0\\xb0\\xd0\\xba\\xd0\\xb0\\xd1\\x8f \\xd0\\xb0\\xd0\\xb1\\xd1\\x80\\xd0\\xb0\\xd0\\xba\\xd0\\xb0\\xd0\\xb4\\xd0\\xb0\\xd0\\xb1\\xd1\\x80\\xd0\\xb0 ))\\xd0\\xa1 \\xd0\\xb4\\xd0\\xbd\\xd0\\xb5\\xd0\\xbc \\xd1\\x80\\xd0\\xbe\\xd0\\xb6\\xd0\\xb4\\xd0\\xb5\\xd0\\xbd\\xd0\\xb8\\xd1\\x8f \\xd0\\xb8 \\xd1\\x81 \\xd0\\xbf\\xd1\\x80\\xd0\\xb5\\xd0\\xb7\\xd0\\xb5\\xd0\\xbd\\xd1\\x82\\xd0\\xb0\\xd1\\x86\\xd0\\xb8\\xd0\\xb5\\xd0\\xb9 )) http://t\\xe2\\x80\\xa6',\n",
              "        b'\\xd0\\x92\\xd1\\x81\\xd0\\xb5 \\xd1\\x83\\xd0\\xb6\\xd0\\xb5 \\xd0\\xba\\xd1\\x83\\xd0\\xbf\\xd0\\xb8\\xd0\\xbb\\xd0\\xb8 \\xd0\\xbd\\xd0\\xb0 \\xd0\\xbd\\xd0\\xb3,\\xd0\\xb0 \\xd1\\x8f \\xd1\\x82\\xd0\\xb0\\xd0\\xba \\xd0\\xb8 \\xd0\\xbd\\xd0\\xb5 \\xd0\\xbd\\xd0\\xb0\\xd1\\x88\\xd0\\xbb\\xd0\\xb0 \\xd0\\xbd\\xd0\\xb8 \\xd1\\x87\\xd0\\xb5\\xd0\\xb3\\xd0\\xbe:,(',\n",
              "        b'\\xd0\\x91\\xd0\\xb8\\xd0\\xbb\\xd0\\xbb, \\xd1\\x82\\xd0\\xb5\\xd0\\xb1\\xd0\\xb5 \\xd0\\xb1\\xd1\\x8b \\xd0\\xbc\\xd0\\xbe\\xd0\\xbd\\xd0\\xb0\\xd1\\x88\\xd0\\xba\\xd1\\x83 \\xd0\\xb8\\xd0\\xbb\\xd0\\xb8 \\xd0\\xba\\xd0\\xb0\\xd0\\xba\\xd1\\x83\\xd1\\x8e \\xd0\\xbd\\xd0\\xb8\\xd0\\xb1\\xd1\\x83\\xd0\\xb4\\xd1\\x8c \\xd0\\x9b\\xd0\\xbe\\xd1\\x81 \\xd0\\x90\\xd0\\xbd\\xd0\\xb4\\xd0\\xb6\\xd0\\xb5\\xd0\\xbb\\xd0\\xb5\\xd0\\xb2\\xd1\\x81\\xd1\\x83\\xd1\\x8e \\xd1\\x88\\xd0\\xbb\\xd1\\x8e\\xd1\\x88\\xd0\\xba\\xd1\\x83 \\xd1\\x81\\xd1\\x8b\\xd0\\xb3\\xd1\\x80\\xd0\\xb0\\xd1\\x82\\xd1\\x8c :D \\xd0\\x9c\\xd0\\xbe\\xd0\\xb6\\xd0\\xbd\\xd0\\xbe \\xd0\\xb5\\xd1\\x89\\xd1\\x91 \\xd0\\xb0\\xd0\\xbb\\xd0\\xba\\xd0\\xb0\\xd1\\x88\\xd0\\xb0 \\xd1\\x82\\xd1\\x83\\xd0\\xbd\\xd0\\xb5\\xd1\\x8f\\xd0\\xb4\\xd1\\x86\\xd0\\xb0 \\xd0\\xba\\xd1\\x81\\xd1\\x82\\xd0\\xb0\\xd1\\x82\\xd0\\xb8 :3 http://t.co/ZoW4S8Q5Ix',\n",
              "        b'@Luke5__SOS \\xd0\\xbe \\xd0\\xba\\xd0\\xb0\\xd0\\xba\\xd0\\xbe\\xd0\\xb9 \\xd0\\xba\\xd1\\x80\\xd0\\xbe\\xd0\\xb2\\xd0\\xb0\\xd1\\x82\\xd0\\xb8? :\\xd0\\xbe \\xd1\\x82\\xd0\\xb5\\xd0\\xb1\\xd0\\xb5 \\xd0\\xbd\\xd0\\xb5 \\xd1\\x83\\xd0\\xb4\\xd0\\xbe\\xd0\\xb1\\xd0\\xbd\\xd0\\xbe? :(',\n",
              "        b'RT @alena___alenka: @kipriyanovaaaaa \\xd0\\xb4\\xd0\\xb0:(',\n",
              "        b'\\xd0\\xbf\\xd0\\xb8\\xd0\\xb7\\xd0\\xb4\\xd0\\xb5\\xd1\\x86 \\xd0\\xbd\\xd0\\xbe\\xd1\\x87\\xd0\\xba\\xd0\\xb0 - \\xd1\\x83\\xd1\\x82\\xd1\\x80\\xd0\\xb5\\xd1\\x87\\xd0\\xba\\xd0\\xbe, \\xd0\\xba\\xd0\\xbe\\xd0\\xbd\\xd0\\xb5\\xd1\\x87\\xd0\\xbd\\xd0\\xbe. \\xd0\\x97\\xd0\\xb0\\xd1\\x82\\xd0\\xbe \\xd0\\xbf\\xd0\\xbe\\xd1\\x80\\xd0\\xb6\\xd0\\xb0\\xd0\\xbb\\xd0\\xb8 \\xd0\\xbe\\xd1\\x82 \\xd0\\xb4\\xd1\\x83\\xd1\\x88\\xd0\\x98)',\n",
              "        b'@d_kolobok \\xd0\\xb4\\xd0\\xb0\\xd0\\xb9 \\xd0\\xb1\\xd0\\xbe\\xd0\\xb3 \\xd0\\xb5\\xd0\\xbc\\xd1\\x83 \\xd1\\x81\\xd0\\xb8\\xd0\\xbb! \\xd0\\xa1 \\xd0\\xb2\\xd0\\xbe\\xd1\\x81\\xd1\\x81\\xd1\\x82\\xd0\\xb0\\xd0\\xbd\\xd0\\xbe\\xd0\\xb2\\xd0\\xbb\\xd0\\xb5\\xd0\\xbd\\xd0\\xb8\\xd0\\xb5\\xd0\\xbc \\xd1\\x81\\xd0\\xbe\\xd0\\xb3\\xd0\\xbb\\xd0\\xb0\\xd1\\x81\\xd0\\xb5\\xd0\\xbd, \\xd0\\xbf\\xd1\\x80\\xd0\\xbe\\xd1\\x85\\xd0\\xbe\\xd0\\xb4\\xd0\\xb8\\xd0\\xbb \\xd1\\x87\\xd0\\xb5\\xd1\\x80\\xd0\\xb5\\xd0\\xb7 \\xd0\\xb0\\xd0\\xbd\\xd0\\xb0\\xd0\\xbb\\xd0\\xbe\\xd0\\xb3\\xd0\\xb8\\xd1\\x87\\xd0\\xbd\\xd0\\xbe\\xd0\\xb5(',\n",
              "        b'\\xd0\\x9a\\xd1\\x83\\xd0\\xb4\\xd0\\xb0 \\xd0\\xbe\\xd1\\x82\\xd0\\xbf\\xd1\\x80\\xd0\\xb0\\xd0\\xb2\\xd0\\xb8\\xd1\\x82\\xd1\\x8c\\xd1\\x81\\xd1\\x8f \\xd0\\xbd\\xd0\\xb0 \\xd0\\xbc\\xd0\\xb0\\xd1\\x88\\xd0\\xb8\\xd0\\xbd\\xd0\\xb5 \\xd0\\xb2\\xd1\\x80\\xd0\\xb5\\xd0\\xbc\\xd0\\xb5\\xd0\\xbd\\xd0\\xb8? \\xe2\\x80\\x94 \\xd0\\xb2 \\xd0\\xbb\\xd0\\xbe\\xd0\\xbd\\xd0\\xb4\\xd0\\xbe\\xd0\\xbd) http://t.co/rdIHdRpXKI',\n",
              "        b'\\xd0\\x90 \\xd0\\xb5\\xd1\\x89\\xd1\\x91 \\xd0\\xb2\\xd1\\x81\\xd0\\xb5\\xd0\\xbc \\xd0\\xbf\\xd0\\xbb\\xd0\\xb5\\xd0\\xb2\\xd0\\xb0\\xd1\\x82\\xd1\\x8c \\xd0\\xbd\\xd0\\xb0 \\xd0\\xb7\\xd0\\xb0\\xd0\\xba\\xd0\\xbe\\xd0\\xbd \"\\xd0\\xbe \\xd0\\xba\\xd1\\x83\\xd1\\x80\\xd0\\xb5\\xd0\\xbd\\xd0\\xb8\\xd0\\xb8 \\xd0\\xb2 \\xd0\\xbe\\xd0\\xb1\\xd1\\x89\\xd0\\xb5\\xd1\\x81\\xd1\\x82\\xd0\\xb2\\xd0\\xb5\\xd0\\xbd\\xd0\\xbd\\xd1\\x8b\\xd1\\x85 \\xd0\\xbc\\xd0\\xb5\\xd1\\x81\\xd1\\x82\\xd0\\xb0\\xd1\\x85\" :|',\n",
              "        b'\\xd0\\x9f\\xd1\\x80\\xd0\\xbe\\xd0\\xb2\\xd0\\xbe\\xd0\\xb4\\xd0\\xb8\\xd0\\xbb\\xd0\\xb0 \\xd0\\xbb\\xd1\\x8e\\xd0\\xb1\\xd0\\xb8\\xd0\\xbc\\xd0\\xbe\\xd0\\xb3\\xd0\\xbe.(( \\xd0\\x9d\\xd0\\xbe \\xd0\\xbd\\xd0\\xb8\\xd1\\x87\\xd0\\xb5\\xd0\\xb3\\xd0\\xbe \\xd0\\xb2 \\xd0\\xbf\\xd1\\x8f\\xd1\\x82\\xd0\\xbd\\xd0\\xb8\\xd1\\x86\\xd1\\x83 \\xd0\\xbf\\xd1\\x80\\xd0\\xb8\\xd0\\xb5\\xd0\\xb4\\xd0\\xb5\\xd1\\x82.',\n",
              "        b'\\xd0\\xbe\\xd0\\xbe\\xd0\\xbe,\\xd0\\xbf\\xd1\\x80\\xd0\\xbe \\xd0\\xb3\\xd0\\xb0\\xd1\\x88\\xd0\\xb8\\xd1\\x88 \\xd1\\x80\\xd0\\xb0\\xd0\\xb7\\xd0\\xb3\\xd0\\xbe\\xd0\\xb2\\xd0\\xbe\\xd1\\x80\\xd1\\x8b,\\xd0\\xb0\\xd1\\x85\\xd0\\xb0\\xd1\\x85\\xd0\\xb0\\n\\xd0\\xbf\\xd1\\x81\\xd1\\x81,\\xd0\\xbf\\xd0\\xb0\\xd1\\x80\\xd0\\xbd\\xd0\\xb8 \\xd0\\xb3\\xd0\\xb5\\xd1\\x80\\xd0\\xbe\\xd0\\xb8\\xd0\\xbd\\xd1\\x87\\xd0\\xb8\\xd0\\xba\\xd0\\xbe\\xd0\\xbc \\xd0\\xbf\\xd0\\xbe\\xd0\\xb1\\xd0\\xb0\\xd0\\xbb\\xd0\\xbe\\xd0\\xb2\\xd0\\xb0\\xd1\\x82\\xd1\\x8c\\xd1\\x81\\xd1\\x8f \\xd0\\xbd\\xd0\\xb5 \\xd1\\x85\\xd0\\xbe\\xd1\\x82\\xd0\\xb8\\xd1\\x82\\xd0\\xb5:D',\n",
              "        b'\\xd0\\x9a\\xd0\\xb0\\xd0\\xba \\xd0\\xb6\\xd0\\xb5 \\xd1\\x85\\xd0\\xbe\\xd1\\x87\\xd1\\x83 \\xd0\\xbd\\xd0\\xb0\\xd1\\x83\\xd1\\x87\\xd0\\xb8\\xd1\\x82\\xd1\\x8c\\xd1\\x81\\xd1\\x8f \\xd0\\xb8\\xd0\\xb3\\xd1\\x80\\xd0\\xb0\\xd1\\x82\\xd1\\x8c \\xd0\\xbd\\xd0\\xb0 \\xd1\\x81\\xd0\\xb8\\xd0\\xbd\\xd1\\x82\\xd0\\xb5\\xd0\\xb7\\xd0\\xb0\\xd1\\x82\\xd0\\xbe\\xd1\\x80\\xd0\\xb5 :(',\n",
              "        b'@LavoAngelina \\xd0\\xbd\\xd0\\xb5 \\xd0\\xb2\\xd0\\xb5\\xd1\\x80\\xd1\\x8e)) \\xd0\\xbd\\xd1\\x83 \\xd0\\xb4\\xd0\\xb0 \\xd0\\xbb\\xd0\\xb0\\xd0\\xb4\\xd0\\xbd\\xd0\\xbe. \\xd1\\x8f \\xd1\\x81\\xd0\\xb5\\xd0\\xb3\\xd0\\xbe\\xd0\\xb4\\xd0\\xbd\\xd1\\x8f \\xd0\\xbf\\xd0\\xbe \\xd1\\x82\\xd0\\xb2\\xd0\\xbe\\xd0\\xb8\\xd0\\xbc \\xd1\\x80\\xd0\\xb5\\xd0\\xba\\xd0\\xbe\\xd0\\xbc\\xd0\\xb5\\xd0\\xbd\\xd0\\xb4\\xd0\\xb0\\xd1\\x86\\xd0\\xb8\\xd1\\x8f\\xd0\\xbc \\xd0\\xb3\\xd0\\xbb\\xd1\\x8f\\xd0\\xbd\\xd1\\x83\\xd0\\xbb \"\\xd0\\x97\\xd0\\xb0\\xd0\\xbc\\xd0\\xb5\\xd1\\x80\\xd0\\xb7\\xd1\\x88\\xd0\\xb8\\xd0\\xb5\".. \\xd0\\xbd\\xd1\\x83 \\xd1\\x8d\\xd1\\x82\\xd0\\xbe \\xd0\\xb2\\xd0\\xb5\\xd0\\xb4\\xd1\\x8c \\xd0\\xb6\\xd1\\x83\\xd1\\x83\\xd1\\x83\\xd1\\x82\\xd1\\x8c... ))',\n",
              "        b'\\xd0\\xa2\\xd1\\x8b \\xd0\\xbb\\xd1\\x8e\\xd0\\xb1\\xd0\\xb8\\xd1\\x88\\xd1\\x8c \\xd0\\xb2\\xd1\\x8b\\xd1\\x81\\xd0\\xbe\\xd0\\xba\\xd0\\xb8\\xd0\\xb5 \\xd0\\xba\\xd0\\xb0\\xd0\\xb1\\xd0\\xbb\\xd1\\x83\\xd0\\xba\\xd0\\xb8? \\xe2\\x80\\x94 \\xd0\\xb0\\xd0\\xb7\\xd0\\xb0\\xd0\\xb7\\xd0\\xb0,\\xd0\\xbd\\xd0\\xb8\\xd1\\x82,\\xd1\\x8f \\xd0\\xb8 \\xd0\\xb1\\xd0\\xb0\\xd0\\xbb\\xd0\\xb5\\xd1\\x82\\xd0\\xba\\xd0\\xb8 \\xd0\\xbd\\xd0\\xb5 \\xd0\\xbe\\xd1\\x87\\xd0\\xb5\\xd0\\xbd\\xd1\\x8c \\xd0\\xbb\\xd1\\x8e\\xd0\\xb1\\xd0\\xbb\\xd1\\x8e:|\\n\\xd1\\x82\\xd0\\xbe\\xd0\\xbb\\xd1\\x8c\\xd0\\xba\\xd0\\xbe \\xd0\\xba\\xd0\\xb5\\xd0\\xb4\\xd1\\x8b http://t.co/Wkz7EEwQOE',\n",
              "        b'\\xd0\\x93\\xd1\\x83\\xd0\\xb1\\xd0\\xb5\\xd1\\x80\\xd0\\xbd\\xd0\\xb8\\xd0\\xb5\\xd0\\xb2 \\xd0\\xbe\\xd0\\xbf\\xd1\\x8f\\xd1\\x82\\xd1\\x8c \\xd0\\xbc\\xd0\\xb0\\xd1\\x82\\xd0\\xb5\\xd1\\x80\\xd0\\xb8\\xd1\\x82\\xd1\\x81\\xd1\\x8f \\xd0\\xb2 \\xd0\\xbf\\xd1\\x80\\xd1\\x8f\\xd0\\xbc\\xd0\\xbe\\xd0\\xbc \\xd1\\x8d\\xd1\\x84\\xd0\\xb8\\xd1\\x80\\xd0\\xb5!))) \\xd0\\xbd\\xd0\\xb5 \\xd0\\xb2\\xd0\\xb5\\xd0\\xb7\\xd0\\xb5\\xd1\\x82 \\xd0\\xbf\\xd0\\xb0\\xd1\\x86\\xd0\\xb0\\xd0\\xbd\\xd1\\x83 http://t.co/bYbkKP4vRN'],\n",
              "       dtype=object)>,\n",
              " <tf.Tensor: shape=(16,), dtype=int64, numpy=array([0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1])>)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_standardization(input_data):\n",
        "\n",
        "    return input_data\n",
        "\n",
        "vocab_size = 10000 # выбрали 10000 а там было 31к\n",
        "seq_len = 100 # сколько токенов в тексте -проходят по всем текстам и выбирают максимум, или берут квантильное -\n",
        "# могут быть выбросы по длинам\n",
        "\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int', # что каждый токен будем переводить в индекс относительно нашего словаря vocab_size\n",
        "    output_sequence_length=seq_len)\n",
        "\n",
        "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
        "text_data = train_data.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(text_data)\n",
        "\n",
        "embedding_dim=200 # 200-мерные вектора будут у каждого токена"
      ],
      "metadata": {
        "id": "JLUgt4Yq6KaC"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myNet(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(myNet, self).__init__()\n",
        "        self.emb = Embedding(vocab_size, embedding_dim, name=\"embedding\")\n",
        "        self.conv1 = Conv1D(200, (3))\n",
        "        self.conv2 = Conv1D(200, (3))\n",
        "        self.gPool = GlobalAveragePooling1D()\n",
        "        self.fc1 = Dense(100, activation='relu')\n",
        "        self.fc2 = Dense(1)\n",
        "\n",
        "\n",
        "    def call(self, x):\n",
        "        x = vectorize_layer(x)\n",
        "        x = self.emb(x)\n",
        "        x1 = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.gPool((x + x1)/2)\n",
        "        x = self.fc1(x)\n",
        "#         x = self.ss(x)\n",
        "        return self.fc2(x)\n",
        "\n",
        "# тут подход что все выделено в класс - ти удобнее писать в таком подходе!!!!\n",
        "# так как еслп будут повторться слои"
      ],
      "metadata": {
        "id": "oDBldNlT6Mjz"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mmodel = myNet()"
      ],
      "metadata": {
        "id": "B-cfrd6R6OUr"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mmodel.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "9DU7X-W16QPq"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mmodel.fit(train_data, validation_data=valid_data, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9qdIG3k6R5g",
        "outputId": "025c17c6-77ee-4be3-8f34-66fa851bc857"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "10633/10633 [==============================] - 1076s 101ms/step - loss: 0.3894 - accuracy: 0.7759 - val_loss: 0.3522 - val_accuracy: 0.7971\n",
            "Epoch 2/5\n",
            "10633/10633 [==============================] - 1084s 102ms/step - loss: 0.3265 - accuracy: 0.8181 - val_loss: 0.3467 - val_accuracy: 0.8094\n",
            "Epoch 3/5\n",
            "10633/10633 [==============================] - 1082s 102ms/step - loss: 0.3052 - accuracy: 0.8332 - val_loss: 0.3447 - val_accuracy: 0.8063\n",
            "Epoch 4/5\n",
            "10633/10633 [==============================] - 1062s 100ms/step - loss: 0.2863 - accuracy: 0.8450 - val_loss: 0.3528 - val_accuracy: 0.8110\n",
            "Epoch 5/5\n",
            "10633/10633 [==============================] - 1072s 101ms/step - loss: 0.2648 - accuracy: 0.8596 - val_loss: 0.3733 - val_accuracy: 0.8083\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4d6e2c1690>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Переобучение уже пошло с 3-й эпохи - и дальше стало только усиливаться"
      ],
      "metadata": {
        "id": "BLL_InvU6VAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = mmodel.predict(valid_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RG8mN9Py6WvP",
        "outputId": "6aca9e5c-63de-41c0-8ffc-15007d731b1f"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3545/3545 [==============================] - 73s 21ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7jL_h5o6YTT",
        "outputId": "436fe4cb-e2fd-44bc-fb89-0c179959253a"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2.9012817e-01],\n",
              "       [ 1.2050204e+00],\n",
              "       [ 9.1390905e+00],\n",
              "       ...,\n",
              "       [-2.3123796e+01],\n",
              "       [ 4.5659134e-01],\n",
              "       [ 4.0750764e-03]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Приведем preds в бинарный вид\n",
        "preds = [int(i[0]>0) for i in preds]"
      ],
      "metadata": {
        "id": "TbrlY0T46Z79"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pred = clf.predict(tfidf_vect.transform(x_test))\n",
        "print(classification_report(preds, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHtsXvkN6blK",
        "outputId": "4d3f0ac0-fe48-4fc4-ded6-125ac81ce73a"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.85      0.80     25459\n",
            "           1       0.86      0.79      0.82     31250\n",
            "\n",
            "    accuracy                           0.82     56709\n",
            "   macro avg       0.81      0.82      0.81     56709\n",
            "weighted avg       0.82      0.82      0.82     56709\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "gJABxhalLVQu",
        "rck5OVqhLVSA"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}