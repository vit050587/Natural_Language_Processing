{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vit050587/Natural_Language_Processing/blob/master/KVA_HW_14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVY9TfMKN0a2"
      },
      "source": [
        "#–£—Ä–æ–∫ 14. –ú–æ–¥–µ–ª—å BERT –∏ GPT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMko5Mvmq7Ml",
        "outputId": "f933e530-c06f-4909-f81e-e0ea83ba46d3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgCPe2deN5sm"
      },
      "source": [
        "–≤–∑—è—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑\n",
        "\n",
        "https://www.kaggle.com/datasets/mrapplexz/bashim-quotes\n",
        "\n",
        "–æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å GPT –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–≤–æ–∏—Ö —Ü–∏—Ç–∞—Ç\n",
        "\n",
        "–≤–∑—è—Ç—å –Ω–æ–≤–æ—Å—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑\n",
        "\n",
        "https://github.com/natasha/corus load_lenta2\n",
        "\n",
        "–Ω–∞–º –ø–æ–Ω–∞–¥–æ–±–∏—Ç—å—Å—è —Å–∞–º —Ç–µ–∫—Å—Ç –∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å T5/ –∏–ª–∏ GPT –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –¥–ª—è —Å—Ç–∞—Ç–µ–π"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HBtsbTHwMuPt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "u_Mi1WxKOBj0"
      },
      "outputs": [],
      "source": [
        "!pip install transformers sentencepiece --quiet\n",
        "#!pip install \"transformers[sentencepiece]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYoTe84IPGU_"
      },
      "source": [
        "##–ó–∞–¥–∞–Ω–∏–µ 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "zgx4bne5PKFg",
        "outputId": "96319b0f-b85f-447c-d288-a43f69f0d874"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        date   rating  \\\n",
              "id                                      \n",
              "1  2004-08-30 11:24:00+00:00  22010.0   \n",
              "2  2004-08-30 11:25:00+00:00  25105.0   \n",
              "3  2004-08-30 11:27:00+00:00   7192.0   \n",
              "\n",
              "                                                 text  \n",
              "id                                                     \n",
              "1   <Ares> ppdv, –≤—Å–µ —é–Ω–∏–∫—Å—ã –æ—á–µ–Ω—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã.. –æ–Ω–∏...  \n",
              "2   <—Ç–æ–º–∞—Ç–∏–∫_—Ä–∞–¥> –∞ —Ç—ã –Ω–µ —á—É–≤—Å—Ç–≤—É–µ—à—å –∫—Ä–∞—Å–æ—Ç—É –º–∏—Ä–∞?...  \n",
              "3   <–î–æ—Ä> \"–º—ã—à–∫–∞, –ø–æ—á–µ–º—É —É —Ç–µ–±—è —Ç–∞–∫–∏–µ –±–æ–ª—å—à–∏–µ –≥–ª–∞–∑...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8607f88-1e94-4044-bac0-4c1258131d33\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>rating</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2004-08-30 11:24:00+00:00</td>\n",
              "      <td>22010.0</td>\n",
              "      <td>&lt;Ares&gt; ppdv, –≤—Å–µ —é–Ω–∏–∫—Å—ã –æ—á–µ–Ω—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã.. –æ–Ω–∏...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2004-08-30 11:25:00+00:00</td>\n",
              "      <td>25105.0</td>\n",
              "      <td>&lt;—Ç–æ–º–∞—Ç–∏–∫_—Ä–∞–¥&gt; –∞ —Ç—ã –Ω–µ —á—É–≤—Å—Ç–≤—É–µ—à—å –∫—Ä–∞—Å–æ—Ç—É –º–∏—Ä–∞?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2004-08-30 11:27:00+00:00</td>\n",
              "      <td>7192.0</td>\n",
              "      <td>&lt;–î–æ—Ä&gt; \"–º—ã—à–∫–∞, –ø–æ—á–µ–º—É —É —Ç–µ–±—è —Ç–∞–∫–∏–µ –±–æ–ª—å—à–∏–µ –≥–ª–∞–∑...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8607f88-1e94-4044-bac0-4c1258131d33')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d8607f88-1e94-4044-bac0-4c1258131d33 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d8607f88-1e94-4044-bac0-4c1258131d33');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-da783a12-8490-4702-8284-a0f8a2f55e9e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-da783a12-8490-4702-8284-a0f8a2f55e9e')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-da783a12-8490-4702-8284-a0f8a2f55e9e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/Natural_Language_Processing/lesson14/archive/dataset.jsonl'\n",
        "\n",
        "with open(DATA_PATH) as f:\n",
        "     df = pd.read_json(DATA_PATH, lines=True).set_index('id')\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rro_k8vEPL2W"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clear_text(text):\n",
        "    clr_text = re.sub(r\"<.*?>\", \" \", text).lower()\n",
        "    clr_text = summary = re.sub(r\"\\s\", \" \", clr_text)\n",
        "    return clr_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "gcgs99ipPNEv",
        "outputId": "2bdf81ad-74d5-4e8e-cbc9-4800e5cfb2d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            date   rating  \\\n",
              "id                                          \n",
              "1      2004-08-30 11:24:00+00:00  22010.0   \n",
              "2      2004-08-30 11:25:00+00:00  25105.0   \n",
              "3      2004-08-30 11:27:00+00:00   7192.0   \n",
              "4      2004-08-30 11:28:00+00:00  29169.0   \n",
              "5      2004-08-30 11:26:00+00:00   7140.0   \n",
              "...                          ...      ...   \n",
              "463644 2020-11-26 06:12:00+00:00    698.0   \n",
              "463645 2020-11-26 06:12:00+00:00    816.0   \n",
              "463646 2020-11-26 06:46:00+00:00     88.0   \n",
              "463647 2020-11-26 07:11:00+00:00    226.0   \n",
              "463648 2020-11-26 07:11:00+00:00    299.0   \n",
              "\n",
              "                                                     text  \\\n",
              "id                                                          \n",
              "1       <Ares> ppdv, –≤—Å–µ —é–Ω–∏–∫—Å—ã –æ—á–µ–Ω—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã.. –æ–Ω–∏...   \n",
              "2       <—Ç–æ–º–∞—Ç–∏–∫_—Ä–∞–¥> –∞ —Ç—ã –Ω–µ —á—É–≤—Å—Ç–≤—É–µ—à—å –∫—Ä–∞—Å–æ—Ç—É –º–∏—Ä–∞?...   \n",
              "3       <–î–æ—Ä> \"–º—ã—à–∫–∞, –ø–æ—á–µ–º—É —É —Ç–µ–±—è —Ç–∞–∫–∏–µ –±–æ–ª—å—à–∏–µ –≥–ª–∞–∑...   \n",
              "4       <PPDV[os2]> \"–ú–∞–ª—å—á–∏–∫–∏, –≤—ã —á—Ç–æ –±–æ–ª—å–Ω—ã–µ, –±–µ–≥–∞—Ç—å ...   \n",
              "5       <Ohtori_Akio> –º—ã - –∫–∞–∫ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∏ - –∂–∏–≤—ë–º —Å ...   \n",
              "...                                                   ...   \n",
              "463644  xxx: —É–≥–∞–¥–∞–π—Ç–µ –Ω–µ –≥—É–≥–ª—è, —á—Ç–æ —Ç–∞–∫–æ–µ –∂–æ–ø–∏–∑–¥–∞–Ω!\\ny...   \n",
              "463645  xxx:\\n–ü–æ—Å–µ—Ç–∏–ª–∞ —à–∞–ª—å–Ω–∞—è –º—ã—Å–ª—å –∑–∞–Ω—è—Ç—å—Å—è —Å–æ–±–æ–π, –∂...   \n",
              "463646  #–≤—Å–µ–±–æ–∂—å—è—Ä–æ—Å–∞\\nxxx: –°—É–¥—å–±–∞ –∞–π—Ç–∏—à–Ω–∏–∫–æ–≤ –≤–æ–æ–±—â–µ –Ω...   \n",
              "463647  –ü—Ä–∏–±—ã–≤—à–∏–µ –Ω–∞ –º–µ—Å—Ç–æ –ø—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–∏—Ç–µ–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏–ª–∏,...   \n",
              "463648  —Ö—Ö—Ö: –≤–æ—Ç —Ä–µ–±—è—Ç–∞ –∏–∑ –∞–Ω–≥–ª–∏–π—Å–∫–æ–π —Ñ–∏—Ä–º—ã TVR (–¥–∞–≤–Ω—ã...   \n",
              "\n",
              "                                               clear_text  \n",
              "id                                                         \n",
              "1         ppdv, –≤—Å–µ —é–Ω–∏–∫—Å—ã –æ—á–µ–Ω—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã.. –æ–Ω–∏ –ø—Ä–æ—Å...  \n",
              "2         –∞ —Ç—ã –Ω–µ —á—É–≤—Å—Ç–≤—É–µ—à—å –∫—Ä–∞—Å–æ—Ç—É –º–∏—Ä–∞?   —á–µ—Å—Ç–Ω–æ –≥–æ...  \n",
              "3         \"–º—ã—à–∫–∞, –ø–æ—á–µ–º—É —É —Ç–µ–±—è —Ç–∞–∫–∏–µ –±–æ–ª—å—à–∏–µ –≥–ª–∞–∑–∞?\" ...  \n",
              "4         \"–º–∞–ª—å—á–∏–∫–∏, –≤—ã —á—Ç–æ –±–æ–ª—å–Ω—ã–µ, –±–µ–≥–∞—Ç—å –≤ –ø–∞–ª–∞—Ç—É –∫...  \n",
              "5         –º—ã - –∫–∞–∫ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∏ - –∂–∏–≤—ë–º —Å —Å—É–±–µ–π–∑–æ–º –ø–æ–¥...  \n",
              "...                                                   ...  \n",
              "463644  xxx: —É–≥–∞–¥–∞–π—Ç–µ –Ω–µ –≥—É–≥–ª—è, —á—Ç–æ —Ç–∞–∫–æ–µ –∂–æ–ø–∏–∑–¥–∞–Ω! yy...  \n",
              "463645  xxx: –ø–æ—Å–µ—Ç–∏–ª–∞ —à–∞–ª—å–Ω–∞—è –º—ã—Å–ª—å –∑–∞–Ω—è—Ç—å—Å—è —Å–æ–±–æ–π, –∂–∏...  \n",
              "463646  #–≤—Å–µ–±–æ–∂—å—è—Ä–æ—Å–∞ xxx: —Å—É–¥—å–±–∞ –∞–π—Ç–∏—à–Ω–∏–∫–æ–≤ –≤–æ–æ–±—â–µ –Ω–µ...  \n",
              "463647  –ø—Ä–∏–±—ã–≤—à–∏–µ –Ω–∞ –º–µ—Å—Ç–æ –ø—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–∏—Ç–µ–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏–ª–∏,...  \n",
              "463648  —Ö—Ö—Ö: –≤–æ—Ç —Ä–µ–±—è—Ç–∞ –∏–∑ –∞–Ω–≥–ª–∏–π—Å–∫–æ–π —Ñ–∏—Ä–º—ã tvr (–¥–∞–≤–Ω—ã...  \n",
              "\n",
              "[81497 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5693ab10-58f0-4b28-82ed-089ca1357917\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>rating</th>\n",
              "      <th>text</th>\n",
              "      <th>clear_text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2004-08-30 11:24:00+00:00</td>\n",
              "      <td>22010.0</td>\n",
              "      <td>&lt;Ares&gt; ppdv, –≤—Å–µ —é–Ω–∏–∫—Å—ã –æ—á–µ–Ω—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã.. –æ–Ω–∏...</td>\n",
              "      <td>ppdv, –≤—Å–µ —é–Ω–∏–∫—Å—ã –æ—á–µ–Ω—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã.. –æ–Ω–∏ –ø—Ä–æ—Å...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2004-08-30 11:25:00+00:00</td>\n",
              "      <td>25105.0</td>\n",
              "      <td>&lt;—Ç–æ–º–∞—Ç–∏–∫_—Ä–∞–¥&gt; –∞ —Ç—ã –Ω–µ —á—É–≤—Å—Ç–≤—É–µ—à—å –∫—Ä–∞—Å–æ—Ç—É –º–∏—Ä–∞?...</td>\n",
              "      <td>–∞ —Ç—ã –Ω–µ —á—É–≤—Å—Ç–≤—É–µ—à—å –∫—Ä–∞—Å–æ—Ç—É –º–∏—Ä–∞?   —á–µ—Å—Ç–Ω–æ –≥–æ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2004-08-30 11:27:00+00:00</td>\n",
              "      <td>7192.0</td>\n",
              "      <td>&lt;–î–æ—Ä&gt; \"–º—ã—à–∫–∞, –ø–æ—á–µ–º—É —É —Ç–µ–±—è —Ç–∞–∫–∏–µ –±–æ–ª—å—à–∏–µ –≥–ª–∞–∑...</td>\n",
              "      <td>\"–º—ã—à–∫–∞, –ø–æ—á–µ–º—É —É —Ç–µ–±—è —Ç–∞–∫–∏–µ –±–æ–ª—å—à–∏–µ –≥–ª–∞–∑–∞?\" ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2004-08-30 11:28:00+00:00</td>\n",
              "      <td>29169.0</td>\n",
              "      <td>&lt;PPDV[os2]&gt; \"–ú–∞–ª—å—á–∏–∫–∏, –≤—ã —á—Ç–æ –±–æ–ª—å–Ω—ã–µ, –±–µ–≥–∞—Ç—å ...</td>\n",
              "      <td>\"–º–∞–ª—å—á–∏–∫–∏, –≤—ã —á—Ç–æ –±–æ–ª—å–Ω—ã–µ, –±–µ–≥–∞—Ç—å –≤ –ø–∞–ª–∞—Ç—É –∫...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2004-08-30 11:26:00+00:00</td>\n",
              "      <td>7140.0</td>\n",
              "      <td>&lt;Ohtori_Akio&gt; –º—ã - –∫–∞–∫ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∏ - –∂–∏–≤—ë–º —Å ...</td>\n",
              "      <td>–º—ã - –∫–∞–∫ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∏ - –∂–∏–≤—ë–º —Å —Å—É–±–µ–π–∑–æ–º –ø–æ–¥...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463644</th>\n",
              "      <td>2020-11-26 06:12:00+00:00</td>\n",
              "      <td>698.0</td>\n",
              "      <td>xxx: —É–≥–∞–¥–∞–π—Ç–µ –Ω–µ –≥—É–≥–ª—è, —á—Ç–æ —Ç–∞–∫–æ–µ –∂–æ–ø–∏–∑–¥–∞–Ω!\\ny...</td>\n",
              "      <td>xxx: —É–≥–∞–¥–∞–π—Ç–µ –Ω–µ –≥—É–≥–ª—è, —á—Ç–æ —Ç–∞–∫–æ–µ –∂–æ–ø–∏–∑–¥–∞–Ω! yy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463645</th>\n",
              "      <td>2020-11-26 06:12:00+00:00</td>\n",
              "      <td>816.0</td>\n",
              "      <td>xxx:\\n–ü–æ—Å–µ—Ç–∏–ª–∞ —à–∞–ª—å–Ω–∞—è –º—ã—Å–ª—å –∑–∞–Ω—è—Ç—å—Å—è —Å–æ–±–æ–π, –∂...</td>\n",
              "      <td>xxx: –ø–æ—Å–µ—Ç–∏–ª–∞ —à–∞–ª—å–Ω–∞—è –º—ã—Å–ª—å –∑–∞–Ω—è—Ç—å—Å—è —Å–æ–±–æ–π, –∂–∏...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463646</th>\n",
              "      <td>2020-11-26 06:46:00+00:00</td>\n",
              "      <td>88.0</td>\n",
              "      <td>#–≤—Å–µ–±–æ–∂—å—è—Ä–æ—Å–∞\\nxxx: –°—É–¥—å–±–∞ –∞–π—Ç–∏—à–Ω–∏–∫–æ–≤ –≤–æ–æ–±—â–µ –Ω...</td>\n",
              "      <td>#–≤—Å–µ–±–æ–∂—å—è—Ä–æ—Å–∞ xxx: —Å—É–¥—å–±–∞ –∞–π—Ç–∏—à–Ω–∏–∫–æ–≤ –≤–æ–æ–±—â–µ –Ω–µ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463647</th>\n",
              "      <td>2020-11-26 07:11:00+00:00</td>\n",
              "      <td>226.0</td>\n",
              "      <td>–ü—Ä–∏–±—ã–≤—à–∏–µ –Ω–∞ –º–µ—Å—Ç–æ –ø—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–∏—Ç–µ–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏–ª–∏,...</td>\n",
              "      <td>–ø—Ä–∏–±—ã–≤—à–∏–µ –Ω–∞ –º–µ—Å—Ç–æ –ø—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–∏—Ç–µ–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏–ª–∏,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463648</th>\n",
              "      <td>2020-11-26 07:11:00+00:00</td>\n",
              "      <td>299.0</td>\n",
              "      <td>—Ö—Ö—Ö: –≤–æ—Ç —Ä–µ–±—è—Ç–∞ –∏–∑ –∞–Ω–≥–ª–∏–π—Å–∫–æ–π —Ñ–∏—Ä–º—ã TVR (–¥–∞–≤–Ω—ã...</td>\n",
              "      <td>—Ö—Ö—Ö: –≤–æ—Ç —Ä–µ–±—è—Ç–∞ –∏–∑ –∞–Ω–≥–ª–∏–π—Å–∫–æ–π —Ñ–∏—Ä–º—ã tvr (–¥–∞–≤–Ω—ã...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>81497 rows √ó 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5693ab10-58f0-4b28-82ed-089ca1357917')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5693ab10-58f0-4b28-82ed-089ca1357917 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5693ab10-58f0-4b28-82ed-089ca1357917');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-38f74077-77d9-40ef-b048-2545d6e52dd8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-38f74077-77d9-40ef-b048-2545d6e52dd8')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-38f74077-77d9-40ef-b048-2545d6e52dd8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df[\"clear_text\"] = df[\"text\"].apply(lambda x: clear_text(x))\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mTPVhWwZPOnH"
      },
      "outputs": [],
      "source": [
        "data = df.loc[:, 'clear_text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaZL8YS6PPyf",
        "outputId": "559090ca-b5cb-46ed-cdc4-07130fc46ac9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "1           ppdv, –≤—Å–µ —é–Ω–∏–∫—Å—ã –æ—á–µ–Ω—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã.. –æ–Ω–∏ –ø—Ä–æ—Å...\n",
              "2           –∞ —Ç—ã –Ω–µ —á—É–≤—Å—Ç–≤—É–µ—à—å –∫—Ä–∞—Å–æ—Ç—É –º–∏—Ä–∞?   —á–µ—Å—Ç–Ω–æ –≥–æ...\n",
              "3           \"–º—ã—à–∫–∞, –ø–æ—á–µ–º—É —É —Ç–µ–±—è —Ç–∞–∫–∏–µ –±–æ–ª—å—à–∏–µ –≥–ª–∞–∑–∞?\" ...\n",
              "4           \"–º–∞–ª—å—á–∏–∫–∏, –≤—ã —á—Ç–æ –±–æ–ª—å–Ω—ã–µ, –±–µ–≥–∞—Ç—å –≤ –ø–∞–ª–∞—Ç—É –∫...\n",
              "5           –º—ã - –∫–∞–∫ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∏ - –∂–∏–≤—ë–º —Å —Å—É–±–µ–π–∑–æ–º –ø–æ–¥...\n",
              "                                ...                        \n",
              "463644    xxx: —É–≥–∞–¥–∞–π—Ç–µ –Ω–µ –≥—É–≥–ª—è, —á—Ç–æ —Ç–∞–∫–æ–µ –∂–æ–ø–∏–∑–¥–∞–Ω! yy...\n",
              "463645    xxx: –ø–æ—Å–µ—Ç–∏–ª–∞ —à–∞–ª—å–Ω–∞—è –º—ã—Å–ª—å –∑–∞–Ω—è—Ç—å—Å—è —Å–æ–±–æ–π, –∂–∏...\n",
              "463646    #–≤—Å–µ–±–æ–∂—å—è—Ä–æ—Å–∞ xxx: —Å—É–¥—å–±–∞ –∞–π—Ç–∏—à–Ω–∏–∫–æ–≤ –≤–æ–æ–±—â–µ –Ω–µ...\n",
              "463647    –ø—Ä–∏–±—ã–≤—à–∏–µ –Ω–∞ –º–µ—Å—Ç–æ –ø—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–∏—Ç–µ–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏–ª–∏,...\n",
              "463648    —Ö—Ö—Ö: –≤–æ—Ç —Ä–µ–±—è—Ç–∞ –∏–∑ –∞–Ω–≥–ª–∏–π—Å–∫–æ–π —Ñ–∏—Ä–º—ã tvr (–¥–∞–≤–Ω—ã...\n",
              "Name: clear_text, Length: 81497, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uyKTTf6LPRPv"
      },
      "outputs": [],
      "source": [
        "text=df['clear_text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mPaaApguPS3H"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def build_text_files(data_json, dest_path):\n",
        "    f = open(dest_path, 'w')\n",
        "    data = ''\n",
        "    for texts in data_json:\n",
        "        summary = str(texts).strip()\n",
        "        data += summary + \"  \"\n",
        "    f.write(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OgD0ur0AcW_p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vBJ1tdHXPUP_"
      },
      "outputs": [],
      "source": [
        "train, test = train_test_split(data, test_size=0.15)\n",
        "\n",
        "build_text_files(train, '/content/drive/MyDrive/Colab Notebooks/Natural_Language_Processing/lesson14/train_dataset.txt')\n",
        "build_text_files(test, '/content/drive/MyDrive/Colab Notebooks/Natural_Language_Processing/lesson14/test_dataset.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pWNJk3CvPVdf",
        "outputId": "e7f46f60-c9ed-49b9-c01c-8f436971cd06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'69272'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "str(len(train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GvpGa9BIPW5-",
        "outputId": "08662e8c-95dc-4522-edae-41afbfa62c13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'12225'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "str(len(test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tLjNXqYPYPP",
        "outputId": "7875a8ca-7c07-448b-bc07-3ccc861b5421"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "459418    –∞–ª–µ–∫—Å–µ–π –∞–Ω—Ç–∏–º–æ–Ω–æ–≤: - –Ω–µ–∑–∞–º–µ–Ω–∏–º—ã—Ö —É –Ω–∞—Å –Ω–µ—Ç!! -...\n",
              "437589    - —É –Ω–∞—Å –Ω–∞ —Å–∞–π—Ç–µ –±–ª–æ–∫–∏ —Å –æ–±—ä—è–≤–ª–µ–Ω–∏—è–º–∏ —Å—ä–µ—Ö–∞–ª–∏....\n",
              "261046    hero_in: —Å–µ–≥–æ–¥–Ω—è —É –º–µ–Ω—è –Ω–∞ –ø–∞—Ä–µ —Å—Ç—É–¥–µ–Ω—Ç –≤—Ç—é—Ö–∏–≤...\n",
              "460716    xxx: —É –º—É–∂–∏–∫–∞ –∫–æ–≥–¥–∞ 37.5, —Ç–æ, –ø–æ –æ—â—É—â–µ–Ω–∏—è–º —Å–º–µ...\n",
              "23943     340102494> –∏–¥–∏ –Ω–∞—Ö—É–π mixa> –æ—á–µ–≤–∏–¥–Ω–æ, —Ç—ã –º–µ–Ω—è —Ç...\n",
              "                                ...                        \n",
              "424944    madbrozzer: –Ω–µ—Ç, –ª—é–¥–∏, –∫–æ—Ç–æ—Ä—ã–º –æ—á–µ–Ω—å –Ω—É–∂–µ–Ω –º–æ–π...\n",
              "463346    –º - –º–æ—Ç–∏–≤–∞—Ü–∏—è. —É–∂–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é –∫–∞–∫ –ª–µ—Ç —á–µ—Ä–µ–∑ 1...\n",
              "419014    dart> —Å—Å—É–∫–∏... —É–∂–µ –ø–æ–ª—á–∞—Å–∞ —Å–∏–≥–Ω–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–¥ –æ–∫...\n",
              "390492    oldsword> –∞–∞–∞–∞–∞ oldsword> —è –¥–∞–ª–ø–∞–µ–ø oldsword> ...\n",
              "421728    xxx: –±—Ä–∏—Ç–≤–∞ –∑–∞ 16—Ç—ã—Ä ‚Äì —ç—Ç–æ –±—É—Ä–∂—É–π—Å—Ç–≤–æ, –¥–∞? yyy...\n",
              "Name: clear_text, Length: 69272, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wJ2H16pcPZkn"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, Trainer, TrainingArguments, AutoModelForCausalLM\n",
        "\n",
        "import torch\n",
        "device = torch.device(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEydGdgKPa7d",
        "outputId": "1437d067-1723-42e9-b42e-e2d1d47e1c03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º large GPT3, –∫–æ—Ç–æ—Ä–∞—è –æ—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞ GPT2\n",
        "model_name = 'sberbank-ai/rugpt3large_based_on_gpt2'\n",
        "#model_name = 'Grossmend/rudialogpt3_medium_based_on_gpt2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
        "\n",
        "train_path = '/content/drive/MyDrive/Colab Notebooks/Natural_Language_Processing/lesson14/train_dataset.txt'\n",
        "test_path = '/content/drive/MyDrive/Colab Notebooks/Natural_Language_Processing/lesson14/test_dataset.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "p8oIQZ-vPczf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85041d0f-7049-4ae2-c004-2f2270a62d1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
        "\n",
        "def load_dataset(train_path, test_path, tokenizer):\n",
        "    train_dataset = TextDataset(\n",
        "          tokenizer=tokenizer,\n",
        "          file_path=train_path,\n",
        "          block_size=128)\n",
        "\n",
        "    test_dataset = TextDataset(\n",
        "          tokenizer=tokenizer,\n",
        "          file_path=test_path,\n",
        "          block_size=128)\n",
        "\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer, mlm=False,\n",
        "    )\n",
        "    return train_dataset, test_dataset, data_collator\n",
        "\n",
        "train_dataset, test_dataset, data_collator = load_dataset(train_path, test_path, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9kYpb4ZSfuFD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "712663f3-77da-49a0-89f7-67e56ecc84cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate==0.20.3 in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.3) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.3) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.3) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.3) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.3) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate==0.20.3) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate==0.20.3) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate==0.20.3) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate==0.20.3) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "#!pip install transformers==4.20.1\n",
        "!pip install accelerate==0.20.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "iwTiq5npPeqd"
      },
      "outputs": [],
      "source": [
        "# Tuning model\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "\n",
        "    \"phrase\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    num_train_epochs=2,\n",
        "    learning_rate=1e-5,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy='no',\n",
        "    report_to='none',\n",
        "\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ILfQ8Pk4Pf9_"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "IzFL4DpNPhNd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bcaaaa6f-0cc8-43f9-b19a-a8118605dba6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='331' max='72038' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  331/72038 02:52 < 10:27:54, 1.90 it/s, Epoch 0.01/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m‚ï≠‚îÄ\u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m‚îÄ‚ïÆ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m in \u001b[92m<cell line: 1>\u001b[0m:\u001b[94m1\u001b[0m                                                                              \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1539\u001b[0m in \u001b[92mtrain\u001b[0m                    \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1536 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0minner_training_loop = find_executable_batch_size(                                 \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1537 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[96mself\u001b[0m._inner_training_loop, \u001b[96mself\u001b[0m._train_batch_size, args.auto_find_batch_size  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1538 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m)                                                                                 \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m1539 \u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m inner_training_loop(                                                       \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1540 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0margs=args,                                                                    \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1541 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mresume_from_checkpoint=resume_from_checkpoint,                                \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1542 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mtrial=trial,                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1888\u001b[0m in \u001b[92m_inner_training_loop\u001b[0m     \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1885 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mscale_after = \u001b[96mself\u001b[0m.scaler.get_scale()                             \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1886 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0moptimizer_was_run = scale_before <= scale_after                   \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1887 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94melse\u001b[0m:                                                                 \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m1888 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[96mself\u001b[0m.optimizer.step()                                             \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1889 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0moptimizer_was_run = \u001b[95mnot\u001b[0m \u001b[96mself\u001b[0m.accelerator.optimizer_step_was_skip  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1890 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m                                                                      \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1891 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mif\u001b[0m optimizer_was_run:                                                 \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/accelerate/\u001b[0m\u001b[1;33moptimizer.py\u001b[0m:\u001b[94m140\u001b[0m in \u001b[92mstep\u001b[0m                      \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m137 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[2m# If we reduced the loss scale, it means the optimizer step was skipped \u001b[0m   \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m138 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[96mself\u001b[0m._is_overflow = scale_after < scale_before                             \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m139 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94melse\u001b[0m:                                                                          \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m140 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[96mself\u001b[0m.optimizer.step(closure)                                               \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m141 \u001b[0m\u001b[2m‚îÇ   \u001b[0m                                                                                       \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m142 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_switch_parameters\u001b[0m(\u001b[96mself\u001b[0m, parameters_map):                                          \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m143 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mfor\u001b[0m param_group \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.optimizer.param_groups:                                    \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/optim/\u001b[0m\u001b[1;33mlr_scheduler.py\u001b[0m:\u001b[94m69\u001b[0m in \u001b[92mwrapper\u001b[0m                \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m  66 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0minstance = instance_ref()                                                 \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m  67 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0minstance._step_count += \u001b[94m1\u001b[0m                                                 \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m  68 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mwrapped = func.\u001b[92m__get__\u001b[0m(instance, \u001b[96mcls\u001b[0m)                                     \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m  69 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m wrapped(*args, **kwargs)                                           \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m  70 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m                                                                              \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m  71 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[2m# Note that the returned function here is no longer a bound method,\u001b[0m           \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m  72 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[2m# so attributes like `__func__` and `__self__` no longer exist.\u001b[0m               \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/optim/\u001b[0m\u001b[1;33moptimizer.py\u001b[0m:\u001b[94m280\u001b[0m in \u001b[92mwrapper\u001b[0m                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m277 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m{\u001b[0mfunc\u001b[33m}\u001b[0m\u001b[33m must return None or a tuple of (\u001b[0m   \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m278 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ      \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mbut got \u001b[0m\u001b[33m{\u001b[0mresult\u001b[33m}\u001b[0m\u001b[33m.\u001b[0m\u001b[33m\"\u001b[0m)                       \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m279 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m                                                                           \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m280 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mout = func(*args, **kwargs)                                                \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m281 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[96mself\u001b[0m._optimizer_step_code()                                                \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m282 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m                                                                           \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m283 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[2m# call optimizer step post hooks\u001b[0m                                           \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/utils/\u001b[0m\u001b[1;33m_contextlib.py\u001b[0m:\u001b[94m115\u001b[0m in \u001b[92mdecorate_context\u001b[0m       \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[1;95m@functools\u001b[0m.wraps(func)                                                                 \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mdecorate_context\u001b[0m(*args, **kwargs):                                                 \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mwith\u001b[0m ctx_factory():                                                                \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m115 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                                   \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m‚îÇ   \u001b[0m                                                                                       \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m decorate_context                                                                \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m118 \u001b[0m                                                                                           \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33moptimization.py\u001b[0m:\u001b[94m466\u001b[0m in \u001b[92mstep\u001b[0m                 \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m463 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m                                                                           \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m464 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[2m# Decay the first and second moment running average coefficient\u001b[0m            \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m465 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[2m# In-place operations to update the averages at the same time\u001b[0m              \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m466 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mexp_avg.mul_(beta1).add_(grad, alpha=(\u001b[94m1.0\u001b[0m - beta1))                        \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m467 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mexp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=\u001b[94m1.0\u001b[0m - beta2)             \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m468 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mdenom = exp_avg_sq.sqrt().add_(group[\u001b[33m\"\u001b[0m\u001b[33meps\u001b[0m\u001b[33m\"\u001b[0m])                               \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m469 \u001b[0m                                                                                           \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n",
              "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 1&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1539</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1536 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>inner_training_loop = find_executable_batch_size(                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1537 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._inner_training_loop, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._train_batch_size, args.auto_find_batch_size  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1538 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>1539 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> inner_training_loop(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1540 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>args=args,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1541 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>resume_from_checkpoint=resume_from_checkpoint,                                <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1542 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>trial=trial,                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1888</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_training_loop</span>     <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1885 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>scale_after = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scaler.get_scale()                             <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1886 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>optimizer_was_run = scale_before &lt;= scale_after                   <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1887 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>1888 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.optimizer.step()                                             <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1889 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>optimizer_was_run = <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator.optimizer_step_was_skip  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1890 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1891 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> optimizer_was_run:                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">optimizer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">140</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">step</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">137 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># If we reduced the loss scale, it means the optimizer step was skipped </span>   <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">138 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._is_overflow = scale_after &lt; scale_before                             <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">139 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>140 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.optimizer.step(closure)                                               <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">141 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">142 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_switch_parameters</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, parameters_map):                                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">143 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> param_group <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.optimizer.param_groups:                                    <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/optim/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">lr_scheduler.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">69</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  66 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>instance = instance_ref()                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  67 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>instance._step_count += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  68 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>wrapped = func.<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__get__</span>(instance, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>)                                     <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>  69 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> wrapped(*args, **kwargs)                                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  70 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  71 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Note that the returned function here is no longer a bound method,</span>           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  72 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># so attributes like `__func__` and `__self__` no longer exist.</span>               <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/optim/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">optimizer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">280</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">277 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"{</span>func<span style=\"color: #808000; text-decoration-color: #808000\">} must return None or a tuple of (</span>   <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">278 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ      </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"but got {</span>result<span style=\"color: #808000; text-decoration-color: #808000\">}.\"</span>)                       <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">279 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>280 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>out = func(*args, **kwargs)                                                <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">281 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._optimizer_step_code()                                                <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">282 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">283 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># call optimizer step post hooks</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_contextlib.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">115</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>       <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@functools</span>.wraps(func)                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>(*args, **kwargs):                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">114 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> ctx_factory():                                                                <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>115 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> decorate_context                                                                <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">118 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">optimization.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">466</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">step</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">463 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">464 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Decay the first and second moment running average coefficient</span>            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">465 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># In-place operations to update the averages at the same time</span>              <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>466 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>exp_avg.mul_(beta1).add_(grad, alpha=(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1.0</span> - beta1))                        <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">467 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1.0</span> - beta2)             <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">468 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>denom = exp_avg_sq.sqrt().add_(group[<span style=\"color: #808000; text-decoration-color: #808000\">\"eps\"</span>])                               <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">469 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QdT5v75PlPl"
      },
      "source": [
        "–æ—Å—Ç–∞–Ω–æ–≤–∏–ª –æ–±—É—á–µ–Ω–∏–µ, 10 —á–∞—Å–æ–≤ –ø—Ä–µ–¥—Å—Ç–æ—è–ª–æ –∂–¥–∞—Ç—å, –∞ —Å –±–æ–ª—å—à–∏–º —Ä–∞–∑–º–µ—Ä–æ–º –±–∞—Ç—á–µ–π –∑–∞–±–∏–≤–∞–ª–∞—Å—å –æ–ø–µ—Ä–∞—Ç–∏–≤–∫–∞ –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—ã."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NxCODfLuPnGm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6899974d-bfe1-4319-aa64-65d05632ee2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "***\n",
            "dago: —É –Ω–∞—Å –≤ –æ—Ñ–∏—Å–µ –Ω–æ–≤–æ–µ —Ä–∞—Å—Ç–µ–Ω–∏–µ grey: –µ—â–µ –æ–¥–Ω–æ–≥–æ –±—É—Ö–≥–∞–ª—Ç–µ—Ä–∞ –≤–∑—è–ª–∏?\n",
            "***\n",
            "--> lizaveta has joined this channel (679@62.105.15.72).   —ç–π –µ–π   –∑–¥—Ä–∞—Å—Ç–≤—É–π—Ç–µ –ª–∏–∑–æ—á–∫–∞   —Å–∫–∞–∂–∏—Ç–µ, –∫–∞–∫–æ–≥–æ —á–∏—Å–ª–∞ –≤—ã —Ä–æ–¥–∏–ª–∏—Å—å?   17   –∫–∞–∫–æ–≥–æ –º–µ—Å—è—Ü–∞?   06   –∫–∞–∫–æ–≥–æ –≥–æ–¥–∞?   1987   –∫–∞–∫–æ–≥–æ —Ö—É—è?   ??????????????????????\n",
            "***\n",
            "—Ñ—É–Ω–∫—Ü–∏—è wolf() –≤ –ø–æ–ª–Ω–æ–ª—É–Ω–∏–µ void –Ω–∞ –ª—É–Ω—É!\n",
            "***\n",
            "vision: –≤ –æ–±—â–µ–º, –µ—Å–ª–∏ —è –Ω–µ –º–æ–≥—É –∑–∞—Å—Ç–∞–≤–∏—Ç—å –æ—Ä–≥–∞–Ω–∏–∑–º —Å–ø–∞—Ç—å, —â–∞ –ø–æ–π–¥—É –º—ã—Ç—å –ø–æ—Å—É–¥—É vision: –∞ —Ç–æ —Ç–∞–º –Ω–µ–±–æ—Å—å —É–∂–µ —Ç–∞—Ä–∞–∫–∞–Ω—ã –≤ —Ü–∞—Ä—è –≥–æ—Ä—ã –∏–≥—Ä–∞—é—Ç\n",
            "***\n",
            "xxx: –∑–Ω–∞–∫–æ–º—ã–µ —Ä—Å—Å–∫–∞–∑—ã–≤–∞–ª–∏. –º—É–∂–∏–∫ —Å–∞–¥–∏–ª—Å—è –≤ –º–∞—à–∏–Ω—É –Ω–∞ –≥–∞—Ä–∞–∂–∞—Ö. –∫—É–¥–∞-—Ç–æ –∑–∞–ø—Ä–æ–ø–∞—Å—Ç–∏–ª—Å—è –Ω–∞–≤–µ—Å–Ω–æ–π –∑–∞–º–æ–∫, –æ–Ω –≤—Ç–æ—Ä–æ–ø—è—Ö –ø—Ä–æ—Å—Ç–æ –∑–∞–º–æ—Ç–∞–ª –¥–≤–µ—Ä—å –ø—Ä–æ–≤–æ–ª–æ–∫–æ–π –∏ —É–µ—Ö–∞–ª. –Ω–æ—á—å—é –≤–æ—Ä—ã –≤—Å–∫—Ä—ã–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≥–∞—Ä–∞–∂–µ–π - —Ç—Ä–∏ –≤–ª–µ–≤–æ –∏ —Ç—Ä–∏ –≤–ø—Ä–∞–≤–æ –æ—Ç –≥–∞—Ä–∞–∂–∞ —ç—Ç–æ–≥–æ –º—É–∂–∏–∫–∞. –µ–≥–æ –≥–∞—Ä–∞–∂ - —Å –ø—Ä–æ–≤–æ–ª–æ–∫–æ–π –≤–º–µ—Å—Ç–æ –∑–∞–º–∫–∞ - –Ω–µ —Ç—Ä–æ–Ω—É–ª–∏, –∞ –Ω–∞ –¥–≤–µ—Ä—è—Ö –∫—Ä–∞—Å–æ–≤–∞–ª–∞—Å—å –Ω–∞–¥–ø–∏—Å—å –±–∞–ª–ª–æ–Ω—á–∏–∫–æ–º \"—Å—É–ø–µ—Ä–∑–∞–º–∫–∏ –Ω–µ –≤–∑–ª–∞–º—ã–≤–∞–µ–º\"\n",
            "***\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sep = '\\n***\\n'  # –ü—Ä–∏–∑–Ω–∞–∫ —Ç–æ–≥–æ, —á—Ç–æ —Ç–≤–∏—Ç –∑–∞–∫–æ–Ω—á–∏–ª—Å—è –∏ –Ω—É–∂–Ω–æ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –µ—â—ë –æ–¥–∏–Ω —Ç–≤–∏—Ç\n",
        "# sep = '\\n27479153\tSandy_mustache\t2021-02-18 16:44:00\t'\n",
        "\n",
        "\n",
        "# –¢–∞–∫ –∫–∞–∫ –º—ã –ø–æ—Å—Ç–æ—è–Ω–Ω–æ —Å—ç–º–ø–ª–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ç–≤–∏—Ç—ã,\n",
        "# –º—ã –±—É–¥–µ–º –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –ø–æ–ª—É—á–∞—Ç—å —Ä–∞–∑–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ\n",
        "prefix = sep.join([''] + random.sample(list(text), k=5) + [''])\n",
        "\n",
        "tokens = tokenizer(prefix, return_tensors='pt')\n",
        "tokens = {k: v.to(model.device) for k, v in tokens.items()}\n",
        "end_token_id = tokenizer.encode('***')[0]  # '***' - —Ç–æ–∫–µ–Ω –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –æ–∫–∞–Ω—á–∏–≤–∞—Ç—å —Ç–≤–∏—Ç\n",
        "\n",
        "# –≤—ã–≤–æ–¥–∏–º —Ç–æ, —á—Ç–æ –º—ã –ø–µ—Ä–µ–¥–∞—ë–º –Ω–∞ –≤—Ö–æ–¥\n",
        "print(prefix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "kVz6qZHjPpB2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e6291199-629b-4b43-e019-08c9f4e71cf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m‚ï≠‚îÄ\u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m‚îÄ‚ïÆ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m in \u001b[92m<cell line: 4>\u001b[0m:\u001b[94m4\u001b[0m                                                                              \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/utils/\u001b[0m\u001b[1;33m_contextlib.py\u001b[0m:\u001b[94m115\u001b[0m in \u001b[92mdecorate_context\u001b[0m       \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[1;95m@functools\u001b[0m.wraps(func)                                                                 \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mdecorate_context\u001b[0m(*args, **kwargs):                                                 \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mwith\u001b[0m ctx_factory():                                                                \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m115 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                                   \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m‚îÇ   \u001b[0m                                                                                       \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m decorate_context                                                                \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m118 \u001b[0m                                                                                           \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/generation/\u001b[0m\u001b[1;33mutils.py\u001b[0m:\u001b[94m1627\u001b[0m in \u001b[92mgenerate\u001b[0m        \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1624 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m**model_kwargs,                                                           \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1625 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m)                                                                             \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1626 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[2m# 13. run beam search\u001b[0m                                                         \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m1627 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.beam_search(                                                      \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1628 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0minput_ids,                                                                \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1629 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mbeam_scorer,                                                              \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1630 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mlogits_processor=logits_processor,                                        \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/generation/\u001b[0m\u001b[1;33mutils.py\u001b[0m:\u001b[94m2932\u001b[0m in \u001b[92mbeam_search\u001b[0m     \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m2929 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m                                                                              \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m2930 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mmodel_inputs = \u001b[96mself\u001b[0m.prepare_inputs_for_generation(input_ids, **model_kwargs)  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m2931 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m                                                                              \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m2932 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0moutputs = \u001b[96mself\u001b[0m(                                                               \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m2933 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m**model_inputs,                                                           \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m2934 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mreturn_dict=\u001b[94mTrue\u001b[0m,                                                         \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m2935 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0moutput_attentions=output_attentions,                                      \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m1501 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/\u001b[0m\u001b[1;33mmodeling_gpt2.py\u001b[0m:\u001b[94m1076\u001b[0m in        \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[92mforward\u001b[0m                                                                                          \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1073 \u001b[0m\u001b[2;33m‚îÇ   ‚îÇ   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1074 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0mreturn_dict = return_dict \u001b[94mif\u001b[0m return_dict \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m \u001b[96mself\u001b[0m.config.use_return  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1075 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m1076 \u001b[2m‚îÇ   ‚îÇ   \u001b[0mtransformer_outputs = \u001b[96mself\u001b[0m.transformer(                                           \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1077 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0minput_ids,                                                                    \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1078 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mpast_key_values=past_key_values,                                              \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1079 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mattention_mask=attention_mask,                                                \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m1501 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/\u001b[0m\u001b[1;33mmodeling_gpt2.py\u001b[0m:\u001b[94m843\u001b[0m in \u001b[92mforward\u001b[0m \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 840 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0mhead_mask = \u001b[96mself\u001b[0m.get_head_mask(head_mask, \u001b[96mself\u001b[0m.config.n_layer)                    \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 841 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 842 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mif\u001b[0m inputs_embeds \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                         \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m 843 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0minputs_embeds = \u001b[96mself\u001b[0m.wte(input_ids)                                           \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 844 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0mposition_embeds = \u001b[96mself\u001b[0m.wpe(position_ids)                                          \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 845 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0mhidden_states = inputs_embeds + position_embeds                                   \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 846 \u001b[0m                                                                                          \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m1501 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33msparse.py\u001b[0m:\u001b[94m162\u001b[0m in \u001b[92mforward\u001b[0m                \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m159 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[96mself\u001b[0m.weight[\u001b[96mself\u001b[0m.padding_idx].fill_(\u001b[94m0\u001b[0m)                                     \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m160 \u001b[0m\u001b[2m‚îÇ   \u001b[0m                                                                                       \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m161 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor) -> Tensor:                                            \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m162 \u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m F.embedding(                                                                \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[96minput\u001b[0m, \u001b[96mself\u001b[0m.weight, \u001b[96mself\u001b[0m.padding_idx, \u001b[96mself\u001b[0m.max_norm,                           \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[96mself\u001b[0m.norm_type, \u001b[96mself\u001b[0m.scale_grad_by_freq, \u001b[96mself\u001b[0m.sparse)                          \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m165 \u001b[0m                                                                                           \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/\u001b[0m\u001b[1;33mfunctional.py\u001b[0m:\u001b[94m2210\u001b[0m in \u001b[92membedding\u001b[0m                 \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m2207 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[2m#   torch.embedding_renorm_\u001b[0m                                                       \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m2208 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[2m# remove once script supports set_grad_enabled\u001b[0m                                    \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m2209 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m_no_grad_embedding_renorm_(weight, \u001b[96minput\u001b[0m, max_norm, norm_type)                    \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m2210 \u001b[2m‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m torch.embedding(weight, \u001b[96minput\u001b[0m, padding_idx, scale_grad_by_freq, sparse)        \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m2211 \u001b[0m                                                                                          \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m2212 \u001b[0m                                                                                          \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚îÇ\u001b[0m   \u001b[2m2213 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92membedding_bag\u001b[0m(                                                                        \u001b[31m‚îÇ\u001b[0m\n",
              "\u001b[31m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n",
              "\u001b[1;91mOutOfMemoryError: \u001b[0mCUDA out of memory. Tried to allocate \u001b[1;36m16.00\u001b[0m MiB \u001b[1m(\u001b[0mGPU \u001b[1;36m0\u001b[0m; \u001b[1;36m14.75\u001b[0m GiB total capacity; \u001b[1;36m14.18\u001b[0m GiB \n",
              "already allocated; \u001b[1;36m4.81\u001b[0m MiB free; \u001b[1;36m14.61\u001b[0m GiB reserved in total by PyTorch\u001b[1m)\u001b[0m If reserved memory is >> allocated memory\n",
              "try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n",
              "PYTORCH_CUDA_ALLOC_CONF\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 4&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_contextlib.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">115</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>       <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@functools</span>.wraps(func)                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>(*args, **kwargs):                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">114 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> ctx_factory():                                                                <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>115 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> decorate_context                                                                <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">118 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/generation/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1627</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">generate</span>        <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1624 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>**model_kwargs,                                                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1625 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1626 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># 13. run beam search</span>                                                         <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>1627 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.beam_search(                                                      <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1628 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>input_ids,                                                                <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1629 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>beam_scorer,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1630 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>logits_processor=logits_processor,                                        <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/generation/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2932</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">beam_search</span>     <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2929 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2930 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>model_inputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.prepare_inputs_for_generation(input_ids, **model_kwargs)  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2931 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>2932 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>(                                                               <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2933 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>**model_inputs,                                                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2934 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>return_dict=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>,                                                         <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2935 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>output_attentions=output_attentions,                                      <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_gpt2.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1076</span> in        <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1073 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1074 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>return_dict = return_dict <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> return_dict <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.config.use_return  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1075 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>1076 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>transformer_outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.transformer(                                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1077 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>input_ids,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1078 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>past_key_values=past_key_values,                                              <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1079 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>attention_mask=attention_mask,                                                <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_gpt2.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">843</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 840 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>head_mask = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.get_head_mask(head_mask, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.config.n_layer)                    <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 841 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 842 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> inputs_embeds <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                         <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span> 843 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>inputs_embeds = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.wte(input_ids)                                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 844 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>position_embeds = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.wpe(position_ids)                                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 845 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>hidden_states = inputs_embeds + position_embeds                                   <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 846 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">sparse.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">162</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">159 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight[<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.padding_idx].fill_(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>)                                     <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">160 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">161 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: Tensor) -&gt; Tensor:                                            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>162 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> F.embedding(                                                                <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.padding_idx, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.max_norm,                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">164 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.norm_type, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scale_grad_by_freq, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sparse)                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">165 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">functional.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2210</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">embedding</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2207 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">#   torch.embedding_renorm_</span>                                                       <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2208 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># remove once script supports set_grad_enabled</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2209 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>_no_grad_embedding_renorm_(weight, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, max_norm, norm_type)                    <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>2210 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> torch.embedding(weight, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, padding_idx, scale_grad_by_freq, sparse)        <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2211 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2212 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2213 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">embedding_bag</span>(                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OutOfMemoryError: </span>CUDA out of memory. Tried to allocate <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.00</span> MiB <span style=\"font-weight: bold\">(</span>GPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.75</span> GiB total capacity; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.18</span> GiB \n",
              "already allocated; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.81</span> MiB free; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.61</span> GiB reserved in total by PyTorch<span style=\"font-weight: bold\">)</span> If reserved memory is &gt;&gt; allocated memory\n",
              "try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n",
              "PYTORCH_CUDA_ALLOC_CONF\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–∞–∫–æ–π —Ç–æ –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ—Ö–æ–∂–∏–π –Ω–∞ —Ç–≤–∏—Ç.\n",
        "\n",
        "size = tokens['input_ids'].shape[1]\n",
        "output = model.generate(\n",
        "    **tokens,\n",
        "    #end_token=end_token_id,\n",
        "    do_sample=False,  # –≤–∫–ª/–≤—ã–∫–ª —Ä–µ–∂–∏–º –≤—ã–¥–∞—á–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –¥.–±. –µ—â—ë –æ–¥–∏–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä\n",
        "    max_length=size+128,\n",
        "    repetition_penalty=4.2,  # —à—Ç—Ä–∞—Ñ –∑–∞ –ø–æ–≤—Ç–æ—Ä—ã –æ–¥–∏–Ω–∞—Ä–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤\n",
        "    temperature=0.7,  # —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞\n",
        "    num_beams=10,  # –°—Ç—Ä–æ–∏–º –¥–µ—Ä–µ–≤–æ –≥–ª—É–±–∏–Ω—ã 10\n",
        "    # no_repeat_ngram_size=3  # ! —Ç—Ä–æ–π–∫–∏ –ø–æ–¥—Ä—è–¥ –∏–¥—É—â–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤ –Ω–µ –¥–æ–ª–∂–Ω—ã –ø–æ–≤—Ç–æ—Ä—è—Ç—å—Å—è (3 –∏ –º–µ–Ω—å—à–µ —Ç–æ–∫–µ–Ω–æ–≤ –Ω–µ –¥–æ–ª–∂–Ω—ã –ø–æ–≤—Ç–æ—Ä—è—Ç—å—Å—è)\n",
        ")\n",
        "\n",
        "decoded = tokenizer.decode(output[0])\n",
        "result = decoded[len(prefix):]\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "tWe__37gPqy9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a9cef67-47bd-4dd6-cb4c-144615ae2a17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yy: —ç—Ç–æ –∂ –Ω–∞–¥–æ –±—ã–ª–æ –¥–æ–¥—É–º–∞—Ç—å—Å—è –¥–æ —Ç–æ–≥–æ, —á—Ç–æ–±—ã –ø—Ä–∏—Ü–µ–ø–∏—Ç—å –∫ –∑–∞–¥–Ω–µ–º—É –±–∞–º–ø–µ—Ä—É –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π —Å–ø–∏–¥–æ–º–µ—Ç—Ä!!! yyy: –¥–∞–∞–∞–∞... xxx: —Ç–∞–∫ –≤–æ—Ç –ø–æ—á–µ–º—É –æ–Ω–∏ –≤—Å–µ –≤—Ä–µ–º—è –µ–∑–¥—è—Ç —Å–æ —Å–ø—É—â–µ–Ω–Ω—ã–º–∏ –∫–æ–ª–µ—Å–∞–º–∏ —Ö—Ö—Ö: –ø–æ—Ç–æ–º—É —á—Ç–æ –∫–æ–≥–¥–∞ –∫–æ–ª–µ—Å–∞ —Å–ø—É—Å—Ç–∏—à—å, –∏—Ö —Å—Ä–∞–∑—É –≤–∏–¥–Ω–æ –ø–æ –∑–∞–ø–∞—Ö—É –≤—ã—Ö–ª–æ–ø–Ω—ã—Ö –≥–∞–∑–æ–≤ –∏–∑ –≤—ã—Ö–ª–æ–ø–Ω–æ–π —Ç—Ä—É–±—ã<s>\n",
            "–Ω–∞–≤–µ—è–Ω–æ –≤—á–µ—Ä–∞—à–Ω–∏–º —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–º –æ —Ç–æ–º, –∫–∞–∫ —Ö–æ—Ä–æ—à–æ –±—ã—Ç—å –±–ª–æ–Ω–¥–∏–Ω–∫–æ–π –∏–ª–∏ –±—Ä—é–Ω–µ—Ç–∫–æ–π :-)...–≤—Å–ø–æ–º–Ω–∏–ª–æ—Å—å –º–Ω–µ —Ç—É—Ç –æ–¥–Ω–æ –∑–∞–±–∞–≤–Ω–æ–µ –≤—ã—Å–∫–∞–∑—ã–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–π –º–æ–µ–π —Ñ—Ä–µ–Ω–¥–µ—Å—Å—ã alexandra_konovaleva\n"
          ]
        }
      ],
      "source": [
        "# –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–∞–∫–æ–π —Ç–æ –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ—Ö–æ–∂–∏–π –Ω–∞ —Ç–≤–∏—Ç.\n",
        "\n",
        "size = tokens['input_ids'].shape[1]\n",
        "output = model.generate(\n",
        "    **tokens,\n",
        "    #end_token=end_token_id,\n",
        "    do_sample=False,  # –≤–∫–ª/–≤—ã–∫–ª —Ä–µ–∂–∏–º –≤—ã–¥–∞—á–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –¥.–±. –µ—â—ë –æ–¥–∏–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä\n",
        "    max_length=size+128,\n",
        "    repetition_penalty=4.2,  # —à—Ç—Ä–∞—Ñ –∑–∞ –ø–æ–≤—Ç–æ—Ä—ã –æ–¥–∏–Ω–∞—Ä–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤\n",
        "    temperature=0.7,  # —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞\n",
        "    num_beams=5,  # –°—Ç—Ä–æ–∏–º –¥–µ—Ä–µ–≤–æ –≥–ª—É–±–∏–Ω—ã 10\n",
        "    # no_repeat_ngram_size=3  # ! —Ç—Ä–æ–π–∫–∏ –ø–æ–¥—Ä—è–¥ –∏–¥—É—â–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤ –Ω–µ –¥–æ–ª–∂–Ω—ã –ø–æ–≤—Ç–æ—Ä—è—Ç—å—Å—è (3 –∏ –º–µ–Ω—å—à–µ —Ç–æ–∫–µ–Ω–æ–≤ –Ω–µ –¥–æ–ª–∂–Ω—ã –ø–æ–≤—Ç–æ—Ä—è—Ç—å—Å—è)\n",
        ")\n",
        "\n",
        "decoded = tokenizer.decode(output[0])\n",
        "result = decoded[len(prefix):]\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8A7G5WjPsqX"
      },
      "source": [
        "##–ó–∞–¥–∞–Ω–∏–µ 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "6kOrYaPtPuoV"
      },
      "outputs": [],
      "source": [
        "!pip install datasets --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "op4T2_XRPwTV"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset_train = load_dataset('IlyaGusev/gazeta', revision=\"v1.0\", split= 'train[:10%]')\n",
        "dataset_test = load_dataset('IlyaGusev/gazeta', revision=\"v1.0\", split= 'test[:10%]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "WMFQILqYPxpm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bdf958b-f434-4563-e418-5315fb4447d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'summary', 'title', 'date', 'url'],\n",
              "    num_rows: 5240\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "dataset_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "rqFD6d_CPy-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e46c59f0-1f98-44ff-f4fc-6d9497e06007"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'summary', 'title', 'date', 'url'],\n",
              "    num_rows: 577\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "dataset_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Spj9fm2VP0PN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d21e6e4e-5508-4139-dcdb-1b59bd4d0b9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'–í NASA –Ω–∞–∑–≤–∞–ª–∏ —á–µ—Ç—ã—Ä–µ –º–∏—Å—Å–∏–∏ –≤ –¥–∞–ª—å–Ω–∏–π –∫–æ—Å–º–æ—Å, –∫–æ—Ç–æ—Ä—ã–µ –≤ —ç—Ç–æ–º –¥–µ—Å—è—Ç–∏–ª–µ—Ç–∏–∏ –º–æ–≥—É—Ç –±—ã—Ç—å –∑–∞–ø—É—â–µ–Ω—ã –∞–º–µ—Ä–∏–∫–∞–Ω—Ü–∞–º–∏. –°—Ä–µ–¥–∏ –Ω–∏—Ö ‚Äî –¥–≤–µ –º–∏—Å—Å–∏–∏ –ø–æ –∏–∑—É—á–µ–Ω–∏—é –í–µ–Ω–µ—Ä—ã, –ø–æ–ª–µ—Ç –∫ —Å–ø—É—Ç–Ω–∏–∫—É –Æ–ø–∏—Ç–µ—Ä–∞ –∏ —ç–∫—Å–ø–µ–¥–∏—Ü–∏—è –∫ –¢—Ä–∏—Ç–æ–Ω—É, —Å–ø—É—Ç–Ω–∏–∫—É –ù–µ–ø—Ç—É–Ω–∞.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "dataset_test['summary'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "3DoBaz3yP1Wu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e7b7da26-81e6-4e5b-8194-a50f06e127a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'–í–µ–Ω–µ—Ä–∞, –ò–æ –∏–ª–∏ –¢—Ä–∏—Ç–æ–Ω: –∫—É–¥–∞ –ø–æ–ª–µ—Ç–∏—Ç NASA'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "dataset_test['title'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "1zc86lUNP3Bu"
      },
      "outputs": [],
      "source": [
        "model_name = \"IlyaGusev/rut5_base_sum_gazeta\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "-sRekkX5P5DG"
      },
      "outputs": [],
      "source": [
        "def len_tok(text):\n",
        "    return len(text.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "EtHiwQu2P6aW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be555e51-2224-4ec0-901b-55efc644abc2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(75, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "max_len_sum, max_len_tl = max(map(len_tok, dataset_train['summary'])), max(map(len_tok, dataset_train['title']))\n",
        "max_len_sum, max_len_tl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "aax7kjJjP7zh"
      },
      "outputs": [],
      "source": [
        "max_len_sum, max_len_tl = 60, 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Gjm6CoteP9UX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f97f2053603f4caaa919ad85d2c77904",
            "fb8053733c694bfa970dedd4d4906a7c",
            "b2063bb9ff324b268d878ee14306c938",
            "4a108260d2e64e0996eeda1346b69d9c",
            "72ce8f361b2242d1aa7bf6b3234b39aa",
            "dbb4c64f48c649dcbf404e5f3559c840",
            "91c1d7e2e85045ec9b74b7bd43ce3c41",
            "06c500e2f6554a5d997eacf0f2752779",
            "3e30bbb1407b43309b98ad019f303037",
            "9247376c001240909817f9f48c13a6af",
            "b06b3a496947439287fa3219677007c7"
          ]
        },
        "outputId": "217399a6-93bb-4a86-ea1d-aa8615e7afc4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/577 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f97f2053603f4caaa919ad85d2c77904"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize(batch):\n",
        "    tokenized_input = tokenizer(batch['summary'], padding='max_length', truncation=True, max_length=max_len_sum)\n",
        "    tokenized_label = tokenizer(batch['title'], padding='max_length', truncation=True, max_length=max_len_tl)\n",
        "\n",
        "    tokenized_input['labels'] = tokenized_label['input_ids']\n",
        "\n",
        "    return tokenized_input\n",
        "\n",
        "dataset_train = dataset_train.map(tokenize, batched=True, batch_size=8)\n",
        "dataset_test = dataset_test.map(tokenize, batched=True, batch_size=8)\n",
        "\n",
        "dataset_train.set_format('numpy', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "dataset_test.set_format('numpy', columns=['input_ids', 'attention_mask', 'labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "qNttmqzqP_Nv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "8bd289c49ce04f82b9b519b1a1891fa3",
            "089a4711fedd4276a67d602431b12856",
            "05d54386bbdb4f2fb31590111b3d0c5c",
            "8a6583e5dd1542c8a16b142e29ead28a",
            "4e43ccfa823d49afa71d39312fdf8bf8",
            "3af5ce377f1d482fbde5f03190e53a72",
            "1588d317aaf34718a35236f07dac06bb",
            "ef813327e783413d9c116722953b407f",
            "17d26c01f1904ef4b377dcb10b2a0dea",
            "6d943a60c5c4477a817ad4cb70c4abe7",
            "331209840afe4f7bafd0d4fc69f748cb",
            "3b3b2ada9ef44bf089835b06579ae568",
            "bd6ad2caa5894ec4a65a1f8d26caaa1c",
            "567c12d3a6bf42268cd22aee4e1cfe3f",
            "0f3d0d27aea54732bb8b13a49df28c41",
            "0de70dec563740eeab4a7016d04dfbbc",
            "daf8cf3c47444edda3d6942413190a4a",
            "42a46423315d435eaf152fe364cd640c",
            "f8af8d19c0974b509d02f0a3df4d899b",
            "13d32eece9a94f898570802b5d6aa0fc",
            "02eacc1605804395ace48da1963a2ae9",
            "0e51e45c61004bfcaf74f6f195e4e4c7"
          ]
        },
        "outputId": "e15ddc1d-d3e1-4fc8-e0e8-7b17d16fc07e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/5240 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8bd289c49ce04f82b9b519b1a1891fa3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/577 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b3b2ada9ef44bf089835b06579ae568"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "dataset_train.save_to_disk('gazeta/train')\n",
        "dataset_test.save_to_disk('gazeta/test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "4El8xz-oQA1H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43092aaf-0fa2-4bbb-adc1-ded782e61229"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  gazeta  phrase  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "-VsS0UDbQCMX"
      },
      "outputs": [],
      "source": [
        "from transformers import T5ForConditionalGeneration, Trainer, TrainingArguments\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqV0qPyuJIYe",
        "outputId": "9a0919b6-d88b-40a5-c9a0-3d1ea7f50b32"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.0.1+cu118)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (16.0.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.9->transformers[torch]) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "65HUhp4mQENn"
      },
      "outputs": [],
      "source": [
        "output_dir = 'gazeta/output'\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    eval_accumulation_steps=1, # Number of eval steps to keep in GPU (the higher, the mor vRAM used)\n",
        "    prediction_loss_only=True, # If I need co compute only loss and not other metrics, setting this to true will use less RAM\n",
        "    learning_rate=0.00001,\n",
        "    evaluation_strategy='steps', # Run evaluation every eval_steps\n",
        "    save_steps=1000, # How often to save a checkpoint\n",
        "    save_total_limit=1, # Number of maximum checkpoints to save\n",
        "    remove_unused_columns=True, # Removes useless columns from the dataset\n",
        "    run_name='run_gazeta', # Wandb run name\n",
        "    logging_steps=500, # How often to log loss to wandb\n",
        "    eval_steps=500, # How often to run evaluation on the val_set\n",
        "    logging_first_step=False, # Whether to log also the very first training step to wandb\n",
        "    load_best_model_at_end=True, # Whether to load the best model found at each evaluation.\n",
        "    metric_for_best_model=\"loss\", # Use loss to evaluate best model.\n",
        "    greater_is_better=False # Best model is the one with the lowest loss, not highest.\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "ILF8haDoQGAl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "b6db3a56-1348-4918-bb6f-9c31bce23f3e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6550' max='6550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6550/6550 28:20, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>8.168900</td>\n",
              "      <td>3.299303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>4.180400</td>\n",
              "      <td>3.108436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>2.892900</td>\n",
              "      <td>2.999117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>2.597100</td>\n",
              "      <td>2.922618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>2.487300</td>\n",
              "      <td>2.877703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>2.472900</td>\n",
              "      <td>2.855094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>2.461700</td>\n",
              "      <td>2.825034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>2.395500</td>\n",
              "      <td>2.821311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>2.396400</td>\n",
              "      <td>2.802715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>2.386400</td>\n",
              "      <td>2.798606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>2.372200</td>\n",
              "      <td>2.794542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>2.360100</td>\n",
              "      <td>2.789386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>2.344600</td>\n",
              "      <td>2.788196</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 24min 7s, sys: 1min 56s, total: 26min 3s\n",
            "Wall time: 28min 23s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=6550, training_loss=3.034733190172501, metrics={'train_runtime': 1701.3775, 'train_samples_per_second': 30.799, 'train_steps_per_second': 3.85, 'total_flos': 4174008606720000.0, 'train_loss': 3.034733190172501, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# –û–±—É—á–µ–Ω–∏–µ. –£ –Ω–∞—Å 10 —ç–ø–æ—Ö.\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset_train,\n",
        "    eval_dataset=dataset_test\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "IJsBH6QsQIs0"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(output_dir + '/model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "fChzj8x4QKe2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "567ae0ce-d1a5-4996-a8a2-ea7df442cd3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUMMARY: | –†–æ—Å—Å–∏–π—Å–∫–∏–µ —Ñ—Ä–µ–≥–∞—Ç—ã ¬´–ê–¥–º–∏—Ä–∞–ª –ú–∞–∫–∞—Ä–æ–≤¬ª –∏ ¬´–ê–¥–º–∏—Ä–∞–ª –ì—Ä–∏–≥–æ—Ä–æ–≤–∏—á¬ª —Å –∫—Ä—ã–ª–∞—Ç—ã–º–∏ —Ä–∞–∫–µ—Ç–∞–º–∏ ¬´–ö–∞–ª–∏–±—Ä-–ù–ö¬ª –ø—Ä–æ—Ö–æ–¥—è—Ç —á–µ—Ä–µ–∑ —Ç—É—Ä–µ—Ü–∫–∏–µ –ø—Ä–æ–ª–∏–≤—ã –ë–æ—Å—Ñ–æ—Ä –∏ –î–∞—Ä–¥–∞–Ω–µ–ª–ª—ã –≤ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –°—Ä–µ–¥–∏–∑–µ–º–Ω–æ–≥–æ –º–æ—Ä—è. –†–∞–Ω–µ–µ —ç—Ç–∏ –∫–æ—Ä–∞–±–ª–∏ —É–∂–µ —É—á–∞—Å—Ç–≤–æ–≤–∞–ª–∏ –≤ –≤–æ–µ–Ω–Ω–æ–π –æ–ø–µ—Ä–∞—Ü–∏–∏ –†–§ –≤ –°–∏—Ä–∏–∏ –∏ —Ç–µ–ø–µ—Ä—å –Ω–∞–ø—Ä–∞–≤–ª—è—é—Ç—Å—è —Ç—É–¥–∞ –Ω–∞ —Ñ–æ–Ω–µ –æ–±–æ—Å—Ç—Ä–∏–≤—à–µ–π—Å—è —Å–∏—Ç—É–∞—Ü–∏–∏ –≤ –ò–¥–ª–∏–±–µ.\n",
            "TITLE: | –°–Ω–æ–≤–∞ –≤ –°–∏—Ä–∏—é: —Ä–æ—Å—Å–∏–π—Å–∫–∏–µ —Ñ—Ä–µ–≥–∞—Ç—ã –∏–¥—É—Ç –≤ –°—Ä–µ–¥–∏–∑–µ–º–Ω–æ–µ –º–æ—Ä–µ\n"
          ]
        }
      ],
      "source": [
        "INX = 100\n",
        "print(\"SUMMARY: | {}\".format(dataset_test['summary'][INX]))\n",
        "print(\"TITLE: | {}\".format(dataset_test['title'][INX]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Cu7kVEk0QMJM"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "ecZ4OoluQNcr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ba4ba15-3997-4c3c-9c50-9818b0c20fc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "output:\n",
            "¬´–ê–¥–º–∏—Ä–∞–ª –ì—Ä–∏–≥–æ—Ä–æ–≤–∏—á¬ª –∏ ¬´–ö–∞–ª–∏–±—Ä-–ù–ö¬ª\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "input_text = dataset_test['summary'][INX]\n",
        "\n",
        "with torch.no_grad():\n",
        "    tokenized_text = tokenizer(input_text, truncation=True, padding=True, return_tensors='pt')\n",
        "\n",
        "    source_ids = tokenized_text['input_ids'].to(device, dtype = torch.long)\n",
        "    source_mask = tokenized_text['attention_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "    generated_ids = model.generate(\n",
        "        input_ids = source_ids,\n",
        "        attention_mask = source_mask,\n",
        "        max_length=512,\n",
        "        num_beams=10,\n",
        "        temperature = 1.3,\n",
        "        repetition_penalty=1,\n",
        "        length_penalty=1,\n",
        "        early_stopping=True,\n",
        "        no_repeat_ngram_size=2  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–æ–≤ n-–≥—Ä–∞–º–º > 2 –∑–∞–ø—Ä–µ—â–µ–Ω–æ.\n",
        "    )\n",
        "\n",
        "    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥–±–∏—Ä–∞—é—Ç—Å—è —ç–∫—Å–ø–µ—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ\n",
        "\n",
        "    pred = tokenizer.decode(generated_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\n",
        "print(\"\\noutput:\\n\" + pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "eKu31oqYQPPN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae433c9e-e263-4a12-8b50-2785e65acf41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUMMARY: | –Æ—Ä–∏–¥–∏—á–µ—Å–∫–∞—è –∫–æ–º–ø–∞–Ω–∏—è –∏–∑ –°–®–ê –ø–æ–¥–∞–ª–∞ –≤ —Å—É–¥ –Ω–∞ Apple –∏ Samsung –∑–∞ –≤—ã–ø—É—Å–∫ —Å–º–∞—Ä—Ç—Ñ–æ–Ω–æ–≤, —á—å–µ –∏–∑–ª—É—á–µ–Ω–∏–µ —è–∫–æ–±—ã –ø—Ä–µ–≤—ã—à–∞–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –∑–∞–∫–æ–Ω–æ–º –Ω–æ—Ä–º—ã. –ü–æ –≤–µ—Ä—Å–∏–∏ –∏—Å—Ç—Ü–∞, –≤–µ–Ω–¥–æ—Ä—ã –ø–æ–¥–≤–µ—Ä–≥–∞—é—Ç –∑–¥–æ—Ä–æ–≤—å–µ —Å–≤–æ–∏—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤ –æ–ø–∞—Å–Ω–æ—Å—Ç–∏. –ú–µ–∂–¥—É —Ç–µ–º –§–µ–¥–µ—Ä–∞–ª—å–Ω–∞—è –∫–æ–º–∏—Å—Å–∏—è –ø–æ —Å–≤—è–∑–∏ –°–®–ê –ø—Ä–æ–≤–µ–ª–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–µ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —É—Ä–æ–≤–Ω—è –∏–∑–ª—É—á–µ–Ω–∏—è –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –≥–∞–¥–∂–µ—Ç–æ–≤ –∏ –ø–æ–¥–µ–ª–∏–ª–∞—Å—å –µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏.\n",
            "TITLE: | –û–ø–∞—Å–Ω–æ–µ –∏–∑–ª—É—á–µ–Ω–∏–µ: –Ω–∞ Apple –∏ Samsung –ø–æ–¥–∞–ª–∏ –≤ —Å—É–¥\n",
            "\n",
            "output:\n",
            "Apple –∏ Samsung –æ–±–≤–∏–Ω–∏–ª–∏ Apple –≤ –æ–ø–∞—Å–Ω–æ—Å—Ç–∏\n"
          ]
        }
      ],
      "source": [
        "INX = 11\n",
        "print(\"SUMMARY: | {}\".format(dataset_test['summary'][INX]))\n",
        "print(\"TITLE: | {}\".format(dataset_test['title'][INX]))\n",
        "\n",
        "input_text = dataset_test['summary'][INX]\n",
        "\n",
        "with torch.no_grad():\n",
        "    tokenized_text = tokenizer(input_text, truncation=True, padding=True, return_tensors='pt')\n",
        "\n",
        "    source_ids = tokenized_text['input_ids'].to(device, dtype = torch.long)\n",
        "    source_mask = tokenized_text['attention_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "    generated_ids = model.generate(\n",
        "        input_ids = source_ids,\n",
        "        attention_mask = source_mask,\n",
        "        max_length=512,\n",
        "        num_beams=10,\n",
        "        temperature = 1.3,\n",
        "        repetition_penalty=1,\n",
        "        length_penalty=1,\n",
        "        early_stopping=True,\n",
        "        no_repeat_ngram_size=2  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–æ–≤ n-–≥—Ä–∞–º–º > 2 –∑–∞–ø—Ä–µ—â–µ–Ω–æ.\n",
        "    )\n",
        "\n",
        "    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥–±–∏—Ä–∞—é—Ç—Å—è —ç–∫—Å–ø–µ—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ\n",
        "    pred = tokenizer.decode(generated_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\n",
        "print(\"\\noutput:\\n\" + pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "jE5ZFr7cRE1x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c4d8a65-9d46-4ebb-9689-170948466fa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUMMARY: | –î–ª—è –±–æ—Ä—å–±—ã —Å —Å –Ω–µ–¥–æ–±—Ä–æ—Å–æ–≤–µ—Å—Ç–Ω—ã–º–∏ –ê–ó–°, –Ω–µ–¥–æ–ª–∏–≤–∞—é—â–∏–º–∏ —Ç–æ–ø–ª–∏–≤–æ, –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–±–æ—Ä—ã, –∞ —Ç–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è. –í —ç—Ç–æ–º –≤–æ–ø—Ä–æ—Å–µ –†–æ—Å—Å—Ç–∞–Ω–¥–∞—Ä—Ç –Ω–∞–º–µ—Ä–µ–Ω –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–ø—ã—Ç, –ø–æ–ª—É—á–µ–Ω–Ω—ã–π –≤ —Å—Ñ–µ—Ä–µ —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–∞–±–æ—Ç—ã –∏–≥—Ä–æ–≤—ã—Ö –∞–≤—Ç–æ–º–∞—Ç–æ–≤.\n",
            "TITLE: | –ë–æ—Ä—å–±–∞ —Å –Ω–µ–¥–æ–ª–∏–≤–æ–º: –∑–∞–ø—Ä–∞–≤–∫–∏ –ø—Ä–æ–≤–µ—Ä—è—Ç —Å–∫—Ä—ã—Ç—ã–º –ø—Ä–∏–±–æ—Ä–æ–º\n",
            "\n",
            "output:\n",
            "–ù–µ–¥–æ–±—Ä–æ—Å–æ–≤–µ—Å—Ç–Ω—ã–µ –ê–ó–° –±—É–¥—É—Ç –ø—Ä–æ–≤–µ—Ä\n"
          ]
        }
      ],
      "source": [
        "INX = 15\n",
        "print(\"SUMMARY: | {}\".format(dataset_test['summary'][INX]))\n",
        "print(\"TITLE: | {}\".format(dataset_test['title'][INX]))\n",
        "\n",
        "input_text = dataset_test['summary'][INX]\n",
        "\n",
        "with torch.no_grad():\n",
        "    tokenized_text = tokenizer(input_text, truncation=True, padding=True, return_tensors='pt')\n",
        "\n",
        "    source_ids = tokenized_text['input_ids'].to(device, dtype = torch.long)\n",
        "    source_mask = tokenized_text['attention_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "    generated_ids = model.generate(\n",
        "        input_ids = source_ids,\n",
        "        attention_mask = source_mask,\n",
        "        max_length=512,\n",
        "        num_beams=10,\n",
        "        temperature = 1.3,\n",
        "        repetition_penalty=1,\n",
        "        length_penalty=1,\n",
        "        early_stopping=True,\n",
        "        no_repeat_ngram_size=2  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–æ–≤ n-–≥—Ä–∞–º–º > 2 –∑–∞–ø—Ä–µ—â–µ–Ω–æ.\n",
        "    )\n",
        "\n",
        "    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥–±–∏—Ä–∞—é—Ç—Å—è —ç–∫—Å–ø–µ—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ\n",
        "    pred = tokenizer.decode(generated_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\n",
        "print(\"\\noutput:\\n\" + pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "edRJSwpvRG2Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c99ed3e-6cd8-4a49-c142-551db5a0ddcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUMMARY: | –ö–æ–º–ø–∞–Ω–∏—è Apple –Ω–∞–º–µ—Ä–µ–Ω–∞ –≤—ã–ø—É—Å—Ç–∏—Ç—å ¬´–±—é–¥–∂–µ—Ç–Ω—ã–π¬ª —Å–º–∞—Ä—Ç—Ñ–æ–Ω iPhone SE 2 –≤ –º–∞—Ä—Ç–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ –≥–æ–¥–∞. –≠—Ç–æ—Ç –≥–∞–¥–∂–µ—Ç —Å—Ç–∞–Ω–µ—Ç –ø—Ä–µ–µ–º–Ω–∏–∫–æ–º iPhone SE –∏ –æ–±–æ–π–¥–µ—Ç—Å—è –ø–æ–∫—É–ø–∞—Ç–µ–ª—é –Ω–µ –¥–æ—Ä–æ–∂–µ $399 –∑–∞ –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å.\n",
            "TITLE: | –ù–æ–≤—ã–π –¥–µ—à–µ–≤—ã–π iPhone: —á—Ç–æ –≥–æ—Ç–æ–≤–∏—Ç Apple\n",
            "\n",
            "output:\n",
            "iPhone –≤—ã–π–¥–µ—Ç –≤ –º–∞—Ä—Ç–µ\n"
          ]
        }
      ],
      "source": [
        "INX = 20\n",
        "print(\"SUMMARY: | {}\".format(dataset_test['summary'][INX]))\n",
        "print(\"TITLE: | {}\".format(dataset_test['title'][INX]))\n",
        "\n",
        "input_text = dataset_test['summary'][INX]\n",
        "\n",
        "with torch.no_grad():\n",
        "    tokenized_text = tokenizer(input_text, truncation=True, padding=True, return_tensors='pt')\n",
        "\n",
        "    source_ids = tokenized_text['input_ids'].to(device, dtype = torch.long)\n",
        "    source_mask = tokenized_text['attention_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "    generated_ids = model.generate(\n",
        "        input_ids = source_ids,\n",
        "        attention_mask = source_mask,\n",
        "        max_length=512,\n",
        "        num_beams=10,\n",
        "        temperature = 1.3,\n",
        "        repetition_penalty=1,\n",
        "        length_penalty=1,\n",
        "        early_stopping=True,\n",
        "        no_repeat_ngram_size=2  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–æ–≤ n-–≥—Ä–∞–º–º > 2 –∑–∞–ø—Ä–µ—â–µ–Ω–æ.\n",
        "    )\n",
        "\n",
        "    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥–±–∏—Ä–∞—é—Ç—Å—è —ç–∫—Å–ø–µ—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ\n",
        "    pred = tokenizer.decode(generated_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\n",
        "print(\"\\noutput:\\n\" + pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX_qdeztRJIY"
      },
      "source": [
        "–í–ø–æ–ª–Ω–µ —Ö–æ—Ä–æ—à–∏–µ –ø–æ–ª—É—á–∞—é—Ç—Å—è –∑–∞–≥–æ–ª–æ–≤–∫–∏. –ö–ª–∞—Å—Å–Ω–æ –≤–∞—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä num_beams=10, –æ–Ω —Å–∏–ª—å–Ω–æ —Ä–µ—à–∞–µ—Ç"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "19JYLw5kHc0iGzIQgUx3lom9EVFojUfB8",
      "authorship_tag": "ABX9TyMzq5r0tzuxxVMWEseth5aO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f97f2053603f4caaa919ad85d2c77904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb8053733c694bfa970dedd4d4906a7c",
              "IPY_MODEL_b2063bb9ff324b268d878ee14306c938",
              "IPY_MODEL_4a108260d2e64e0996eeda1346b69d9c"
            ],
            "layout": "IPY_MODEL_72ce8f361b2242d1aa7bf6b3234b39aa"
          }
        },
        "fb8053733c694bfa970dedd4d4906a7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbb4c64f48c649dcbf404e5f3559c840",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_91c1d7e2e85045ec9b74b7bd43ce3c41",
            "value": "Map: 100%"
          }
        },
        "b2063bb9ff324b268d878ee14306c938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06c500e2f6554a5d997eacf0f2752779",
            "max": 577,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e30bbb1407b43309b98ad019f303037",
            "value": 577
          }
        },
        "4a108260d2e64e0996eeda1346b69d9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9247376c001240909817f9f48c13a6af",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b06b3a496947439287fa3219677007c7",
            "value": " 577/577 [00:00&lt;00:00, 748.32 examples/s]"
          }
        },
        "72ce8f361b2242d1aa7bf6b3234b39aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbb4c64f48c649dcbf404e5f3559c840": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91c1d7e2e85045ec9b74b7bd43ce3c41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06c500e2f6554a5d997eacf0f2752779": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e30bbb1407b43309b98ad019f303037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9247376c001240909817f9f48c13a6af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b06b3a496947439287fa3219677007c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bd289c49ce04f82b9b519b1a1891fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_089a4711fedd4276a67d602431b12856",
              "IPY_MODEL_05d54386bbdb4f2fb31590111b3d0c5c",
              "IPY_MODEL_8a6583e5dd1542c8a16b142e29ead28a"
            ],
            "layout": "IPY_MODEL_4e43ccfa823d49afa71d39312fdf8bf8"
          }
        },
        "089a4711fedd4276a67d602431b12856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3af5ce377f1d482fbde5f03190e53a72",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1588d317aaf34718a35236f07dac06bb",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "05d54386bbdb4f2fb31590111b3d0c5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef813327e783413d9c116722953b407f",
            "max": 5240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17d26c01f1904ef4b377dcb10b2a0dea",
            "value": 5240
          }
        },
        "8a6583e5dd1542c8a16b142e29ead28a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d943a60c5c4477a817ad4cb70c4abe7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_331209840afe4f7bafd0d4fc69f748cb",
            "value": " 5240/5240 [00:00&lt;00:00, 40133.07 examples/s]"
          }
        },
        "4e43ccfa823d49afa71d39312fdf8bf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3af5ce377f1d482fbde5f03190e53a72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1588d317aaf34718a35236f07dac06bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef813327e783413d9c116722953b407f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17d26c01f1904ef4b377dcb10b2a0dea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d943a60c5c4477a817ad4cb70c4abe7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "331209840afe4f7bafd0d4fc69f748cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b3b2ada9ef44bf089835b06579ae568": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd6ad2caa5894ec4a65a1f8d26caaa1c",
              "IPY_MODEL_567c12d3a6bf42268cd22aee4e1cfe3f",
              "IPY_MODEL_0f3d0d27aea54732bb8b13a49df28c41"
            ],
            "layout": "IPY_MODEL_0de70dec563740eeab4a7016d04dfbbc"
          }
        },
        "bd6ad2caa5894ec4a65a1f8d26caaa1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_daf8cf3c47444edda3d6942413190a4a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_42a46423315d435eaf152fe364cd640c",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "567c12d3a6bf42268cd22aee4e1cfe3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8af8d19c0974b509d02f0a3df4d899b",
            "max": 577,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13d32eece9a94f898570802b5d6aa0fc",
            "value": 577
          }
        },
        "0f3d0d27aea54732bb8b13a49df28c41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02eacc1605804395ace48da1963a2ae9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0e51e45c61004bfcaf74f6f195e4e4c7",
            "value": " 577/577 [00:00&lt;00:00, 12184.46 examples/s]"
          }
        },
        "0de70dec563740eeab4a7016d04dfbbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daf8cf3c47444edda3d6942413190a4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42a46423315d435eaf152fe364cd640c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8af8d19c0974b509d02f0a3df4d899b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13d32eece9a94f898570802b5d6aa0fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02eacc1605804395ace48da1963a2ae9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e51e45c61004bfcaf74f6f195e4e4c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}